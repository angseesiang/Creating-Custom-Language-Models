{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "A link for free books / text.\n",
        "https://www.gutenberg.org/"
      ],
      "metadata": {
        "id": "0WaqZ8LmmvON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup & Hyperparameters\n",
        "\n",
        "* Sets up PyTorch.\n",
        "* Defines hyperparameters like batch size, learning rate, embedding size, number of attention heads/layers, etc."
      ],
      "metadata": {
        "id": "Bww3Mec44fTg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpekXBo-mdEe",
        "outputId": "88ffc9d4-b33b-4ecc-b49c-2fa2705aa13b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import mmap\n",
        "import random\n",
        "import pickle\n",
        "import argparse\n",
        "\n",
        "# parser = argparse.ArgumentParser(description='This is a demonstration program')\n",
        "\n",
        "# Here we add an argument to the parser, specifying the expected type, a help message, etc.\n",
        "# parser.add_argument('-batch_size', type=str, required=True, help='Please provide a batch_size')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "\n",
        "# Now we can use the argument value in our program.\n",
        "# print(f'batch size: {args.batch_size}')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# batch_size = args.batch_size # to use the batch_size cmd arg -> python file_name.py -batch_size 32\n",
        "batch_size = 32\n",
        "block_size = 128\n",
        "max_iters = 3000\n",
        "learning_rate = 3e-4\n",
        "eval_iters = 50\n",
        "n_embd = 384\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.2\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "attached the file to colab, then copy the file path. An sample of the linked attached file is below:\n",
        "\n",
        "with open('/content/The Tempest.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "chars = sorted(set(text))\n",
        "print(chars)\n",
        "vocab_size = len(chars)\n",
        "\n"
      ],
      "metadata": {
        "id": "LuD44qHbnRFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Training Data\n",
        "\n",
        "* Reads text from online text.txt.\n",
        "* Extracts the vocabulary (unique characters).\n",
        "* This makes it a character-level language model."
      ],
      "metadata": {
        "id": "qH9ZlI_04py-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/pg84.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "chars = sorted(set(text))\n",
        "print(chars)\n",
        "vocab_size = len(chars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci8VRSVqnRbL",
        "outputId": "1622f7c7-c65b-4863-c1be-a62df4c0547f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '#', '$', '%', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'æ', 'è', 'é', 'ê', 'ô', '—', '‘', '’', '“', '”', '•', '™', '\\ufeff']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenisation (Char ↔ Int Conversion)\n",
        "\n",
        "* Encodes characters into integers for training.\n",
        "\n",
        "* Decodes integers back into characters for text generation."
      ],
      "metadata": {
        "id": "QmDkWV4W41JF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
        "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [string_to_int[c] for c in s]\n",
        "decode = lambda l: ''.join([int_to_string[i] for i in l])\n"
      ],
      "metadata": {
        "id": "Gy8cNZdFnYXM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation\n",
        "\n",
        "* Splits text into training/validation sets.\n",
        "* Generates batches of sequences of length block_size.\n",
        "* Feeds them to the model."
      ],
      "metadata": {
        "id": "JdfB6Qug4_3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.8*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n"
      ],
      "metadata": {
        "id": "1c8aGR6lpdik"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "ofzB70vssS0f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture (Transformer-like)\n",
        "* The code defines a Transformer language model with:\n",
        "   * Token embeddings\n",
        "   * Positional embeddings\n",
        "   * Multi-head self-attention layers\n",
        "   * Feed-forward layers\n",
        "   * Dropout and normalization\n",
        "   \n",
        "Essentially, a mini GPT model."
      ],
      "metadata": {
        "id": "MDrjiJBT6im0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input of size (batch, time-step, channels)\n",
        "        # output of size (batch, time-step, head size)\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)     # (B,T,hs)\n",
        "        q = self.query(x)   # (B,T,hs)\n",
        "\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,hs)\n",
        "        out = wei @ v     # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
        "        return out\n",
        "\n",
        "\n",
        "# [1, 0, 0]\n",
        "# [1, 0.6, 0]\n",
        "# [0, 0.6, 0.4]\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.sa(x)\n",
        "        x = self.ln1(x + y)\n",
        "        y = self.ffwd(x)\n",
        "        x = self.ln2(x + y)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, index, targets=None):\n",
        "        B, T = index.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x)    # (B,T,C)\n",
        "        x = self.ln_f(x)      # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, index, max_new_tokens):\n",
        "        # index is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            index_cond = index[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self.forward(index_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
        "        return index\n",
        "\n",
        "\n",
        "model = GPTLanguageModel(vocab_size)\n",
        "# print('loading model parameters...')\n",
        "# with open('model-01.pkl', 'rb') as f:\n",
        "#     model = pickle.load(f)\n",
        "# print('loaded successfully!')\n",
        "m = model.to(device)\n"
      ],
      "metadata": {
        "id": "fjoEo95KqLLt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop\n",
        "\n",
        "* Runs for max_iters iterations.\n",
        "* Uses cross-entropy loss.\n",
        "* Optimizer = AdamW with learning rate scheduling.\n",
        "* Every few iterations, evaluates on validation data."
      ],
      "metadata": {
        "id": "tDuoRbqL6TdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    print(iter)\n",
        "    if iter % eval_iters == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model.forward(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC4dxUQarY8n",
        "outputId": "5dad8d79-3ea6-4424-9cee-8c68550d7c45"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1.8653767108917236\n",
            "525\n",
            "1.8872019052505493\n",
            "526\n",
            "1.888045310974121\n",
            "527\n",
            "1.8794989585876465\n",
            "528\n",
            "1.8652538061141968\n",
            "529\n",
            "1.83613920211792\n",
            "530\n",
            "1.9052132368087769\n",
            "531\n",
            "1.826636552810669\n",
            "532\n",
            "1.8284603357315063\n",
            "533\n",
            "1.8207699060440063\n",
            "534\n",
            "1.8721842765808105\n",
            "535\n",
            "1.8440403938293457\n",
            "536\n",
            "1.8314228057861328\n",
            "537\n",
            "1.8289129734039307\n",
            "538\n",
            "1.88482666015625\n",
            "539\n",
            "1.8440027236938477\n",
            "540\n",
            "1.882112741470337\n",
            "541\n",
            "1.8913227319717407\n",
            "542\n",
            "1.8631885051727295\n",
            "543\n",
            "1.8516926765441895\n",
            "544\n",
            "1.8419276475906372\n",
            "545\n",
            "1.8533202409744263\n",
            "546\n",
            "1.826593041419983\n",
            "547\n",
            "1.8542253971099854\n",
            "548\n",
            "1.8427152633666992\n",
            "549\n",
            "1.8540362119674683\n",
            "550\n",
            "step: 550, train loss: 1.779, val loss: 1.937\n",
            "1.8390722274780273\n",
            "551\n",
            "1.834022045135498\n",
            "552\n",
            "1.8862407207489014\n",
            "553\n",
            "1.8339762687683105\n",
            "554\n",
            "1.8507835865020752\n",
            "555\n",
            "1.8400150537490845\n",
            "556\n",
            "1.8567748069763184\n",
            "557\n",
            "1.8007320165634155\n",
            "558\n",
            "1.8411152362823486\n",
            "559\n",
            "1.8468867540359497\n",
            "560\n",
            "1.8346835374832153\n",
            "561\n",
            "1.778196096420288\n",
            "562\n",
            "1.8116657733917236\n",
            "563\n",
            "1.831639289855957\n",
            "564\n",
            "1.8553940057754517\n",
            "565\n",
            "1.8555855751037598\n",
            "566\n",
            "1.790730595588684\n",
            "567\n",
            "1.8332152366638184\n",
            "568\n",
            "1.8470134735107422\n",
            "569\n",
            "1.8261553049087524\n",
            "570\n",
            "1.8378875255584717\n",
            "571\n",
            "1.8369404077529907\n",
            "572\n",
            "1.8514058589935303\n",
            "573\n",
            "1.8110194206237793\n",
            "574\n",
            "1.8683369159698486\n",
            "575\n",
            "1.8411728143692017\n",
            "576\n",
            "1.82675302028656\n",
            "577\n",
            "1.8510746955871582\n",
            "578\n",
            "1.8892114162445068\n",
            "579\n",
            "1.8324377536773682\n",
            "580\n",
            "1.7982838153839111\n",
            "581\n",
            "1.8200404644012451\n",
            "582\n",
            "1.8272862434387207\n",
            "583\n",
            "1.8023357391357422\n",
            "584\n",
            "1.821496844291687\n",
            "585\n",
            "1.816612720489502\n",
            "586\n",
            "1.834668755531311\n",
            "587\n",
            "1.8432579040527344\n",
            "588\n",
            "1.8300354480743408\n",
            "589\n",
            "1.7878963947296143\n",
            "590\n",
            "1.807265043258667\n",
            "591\n",
            "1.8063712120056152\n",
            "592\n",
            "1.8068305253982544\n",
            "593\n",
            "1.8803224563598633\n",
            "594\n",
            "1.7906712293624878\n",
            "595\n",
            "1.8383569717407227\n",
            "596\n",
            "1.7899391651153564\n",
            "597\n",
            "1.8090457916259766\n",
            "598\n",
            "1.8424617052078247\n",
            "599\n",
            "1.8280367851257324\n",
            "600\n",
            "step: 600, train loss: 1.748, val loss: 1.920\n",
            "1.7899956703186035\n",
            "601\n",
            "1.8082541227340698\n",
            "602\n",
            "1.8123528957366943\n",
            "603\n",
            "1.7841517925262451\n",
            "604\n",
            "1.8309712409973145\n",
            "605\n",
            "1.8662850856781006\n",
            "606\n",
            "1.813647985458374\n",
            "607\n",
            "1.7656954526901245\n",
            "608\n",
            "1.8094234466552734\n",
            "609\n",
            "1.8158549070358276\n",
            "610\n",
            "1.8230347633361816\n",
            "611\n",
            "1.774791955947876\n",
            "612\n",
            "1.8296736478805542\n",
            "613\n",
            "1.8202550411224365\n",
            "614\n",
            "1.8194754123687744\n",
            "615\n",
            "1.8159270286560059\n",
            "616\n",
            "1.7972960472106934\n",
            "617\n",
            "1.8343377113342285\n",
            "618\n",
            "1.7997357845306396\n",
            "619\n",
            "1.8271963596343994\n",
            "620\n",
            "1.7913668155670166\n",
            "621\n",
            "1.801652431488037\n",
            "622\n",
            "1.823278784751892\n",
            "623\n",
            "1.8310331106185913\n",
            "624\n",
            "1.8704016208648682\n",
            "625\n",
            "1.810826301574707\n",
            "626\n",
            "1.7973006963729858\n",
            "627\n",
            "1.7937122583389282\n",
            "628\n",
            "1.7943577766418457\n",
            "629\n",
            "1.818207859992981\n",
            "630\n",
            "1.8045964241027832\n",
            "631\n",
            "1.7624605894088745\n",
            "632\n",
            "1.7922859191894531\n",
            "633\n",
            "1.8728652000427246\n",
            "634\n",
            "1.777869462966919\n",
            "635\n",
            "1.814972996711731\n",
            "636\n",
            "1.7442879676818848\n",
            "637\n",
            "1.7703096866607666\n",
            "638\n",
            "1.7994427680969238\n",
            "639\n",
            "1.7648975849151611\n",
            "640\n",
            "1.7681914567947388\n",
            "641\n",
            "1.7760193347930908\n",
            "642\n",
            "1.735784888267517\n",
            "643\n",
            "1.7640148401260376\n",
            "644\n",
            "1.8098589181900024\n",
            "645\n",
            "1.8189867734909058\n",
            "646\n",
            "1.8551115989685059\n",
            "647\n",
            "1.8287432193756104\n",
            "648\n",
            "1.7566300630569458\n",
            "649\n",
            "1.807227373123169\n",
            "650\n",
            "step: 650, train loss: 1.718, val loss: 1.875\n",
            "1.8173803091049194\n",
            "651\n",
            "1.7820560932159424\n",
            "652\n",
            "1.780362844467163\n",
            "653\n",
            "1.7693161964416504\n",
            "654\n",
            "1.732816219329834\n",
            "655\n",
            "1.7982990741729736\n",
            "656\n",
            "1.7719714641571045\n",
            "657\n",
            "1.7592788934707642\n",
            "658\n",
            "1.753600835800171\n",
            "659\n",
            "1.7704083919525146\n",
            "660\n",
            "1.761721134185791\n",
            "661\n",
            "1.7962605953216553\n",
            "662\n",
            "1.7711248397827148\n",
            "663\n",
            "1.7945563793182373\n",
            "664\n",
            "1.7197959423065186\n",
            "665\n",
            "1.7278136014938354\n",
            "666\n",
            "1.810499906539917\n",
            "667\n",
            "1.8426704406738281\n",
            "668\n",
            "1.783348798751831\n",
            "669\n",
            "1.787071704864502\n",
            "670\n",
            "1.7801134586334229\n",
            "671\n",
            "1.7570621967315674\n",
            "672\n",
            "1.8119356632232666\n",
            "673\n",
            "1.7936890125274658\n",
            "674\n",
            "1.8117780685424805\n",
            "675\n",
            "1.7756850719451904\n",
            "676\n",
            "1.7585046291351318\n",
            "677\n",
            "1.7964208126068115\n",
            "678\n",
            "1.8274812698364258\n",
            "679\n",
            "1.7529008388519287\n",
            "680\n",
            "1.7694834470748901\n",
            "681\n",
            "1.7344810962677002\n",
            "682\n",
            "1.7399260997772217\n",
            "683\n",
            "1.750436782836914\n",
            "684\n",
            "1.7620002031326294\n",
            "685\n",
            "1.7525267601013184\n",
            "686\n",
            "1.7832896709442139\n",
            "687\n",
            "1.8070192337036133\n",
            "688\n",
            "1.704046368598938\n",
            "689\n",
            "1.7271385192871094\n",
            "690\n",
            "1.786379098892212\n",
            "691\n",
            "1.7562692165374756\n",
            "692\n",
            "1.7738556861877441\n",
            "693\n",
            "1.782613754272461\n",
            "694\n",
            "1.7600536346435547\n",
            "695\n",
            "1.8146626949310303\n",
            "696\n",
            "1.7668523788452148\n",
            "697\n",
            "1.7580466270446777\n",
            "698\n",
            "1.8039650917053223\n",
            "699\n",
            "1.7761797904968262\n",
            "700\n",
            "step: 700, train loss: 1.665, val loss: 1.867\n",
            "1.7476317882537842\n",
            "701\n",
            "1.7537813186645508\n",
            "702\n",
            "1.8060693740844727\n",
            "703\n",
            "1.7719402313232422\n",
            "704\n",
            "1.7500574588775635\n",
            "705\n",
            "1.7794333696365356\n",
            "706\n",
            "1.7321135997772217\n",
            "707\n",
            "1.8045384883880615\n",
            "708\n",
            "1.726900339126587\n",
            "709\n",
            "1.7598308324813843\n",
            "710\n",
            "1.7993789911270142\n",
            "711\n",
            "1.746527910232544\n",
            "712\n",
            "1.7300212383270264\n",
            "713\n",
            "1.7405328750610352\n",
            "714\n",
            "1.7349209785461426\n",
            "715\n",
            "1.7863378524780273\n",
            "716\n",
            "1.7199362516403198\n",
            "717\n",
            "1.7403230667114258\n",
            "718\n",
            "1.7291224002838135\n",
            "719\n",
            "1.7892720699310303\n",
            "720\n",
            "1.770207166671753\n",
            "721\n",
            "1.721364974975586\n",
            "722\n",
            "1.7247226238250732\n",
            "723\n",
            "1.740662932395935\n",
            "724\n",
            "1.7776646614074707\n",
            "725\n",
            "1.715416431427002\n",
            "726\n",
            "1.7269303798675537\n",
            "727\n",
            "1.7136977910995483\n",
            "728\n",
            "1.7373775243759155\n",
            "729\n",
            "1.767246961593628\n",
            "730\n",
            "1.7548670768737793\n",
            "731\n",
            "1.7339884042739868\n",
            "732\n",
            "1.7627300024032593\n",
            "733\n",
            "1.739246129989624\n",
            "734\n",
            "1.7149537801742554\n",
            "735\n",
            "1.7624881267547607\n",
            "736\n",
            "1.7571582794189453\n",
            "737\n",
            "1.7485904693603516\n",
            "738\n",
            "1.7480769157409668\n",
            "739\n",
            "1.6890136003494263\n",
            "740\n",
            "1.7345635890960693\n",
            "741\n",
            "1.74855375289917\n",
            "742\n",
            "1.7501280307769775\n",
            "743\n",
            "1.7854361534118652\n",
            "744\n",
            "1.6904323101043701\n",
            "745\n",
            "1.7586395740509033\n",
            "746\n",
            "1.7582011222839355\n",
            "747\n",
            "1.7417961359024048\n",
            "748\n",
            "1.673353672027588\n",
            "749\n",
            "1.739511251449585\n",
            "750\n",
            "step: 750, train loss: 1.642, val loss: 1.844\n",
            "1.7270172834396362\n",
            "751\n",
            "1.7058935165405273\n",
            "752\n",
            "1.7450895309448242\n",
            "753\n",
            "1.6843469142913818\n",
            "754\n",
            "1.706041932106018\n",
            "755\n",
            "1.7289588451385498\n",
            "756\n",
            "1.6611642837524414\n",
            "757\n",
            "1.6953483819961548\n",
            "758\n",
            "1.7365946769714355\n",
            "759\n",
            "1.685762643814087\n",
            "760\n",
            "1.6940973997116089\n",
            "761\n",
            "1.7300910949707031\n",
            "762\n",
            "1.6795730590820312\n",
            "763\n",
            "1.6673829555511475\n",
            "764\n",
            "1.6922328472137451\n",
            "765\n",
            "1.7426987886428833\n",
            "766\n",
            "1.719006896018982\n",
            "767\n",
            "1.7279820442199707\n",
            "768\n",
            "1.7542262077331543\n",
            "769\n",
            "1.7259042263031006\n",
            "770\n",
            "1.7229969501495361\n",
            "771\n",
            "1.7260017395019531\n",
            "772\n",
            "1.7214795351028442\n",
            "773\n",
            "1.6898764371871948\n",
            "774\n",
            "1.6744439601898193\n",
            "775\n",
            "1.6951173543930054\n",
            "776\n",
            "1.7080029249191284\n",
            "777\n",
            "1.7158372402191162\n",
            "778\n",
            "1.6985440254211426\n",
            "779\n",
            "1.7009704113006592\n",
            "780\n",
            "1.7293287515640259\n",
            "781\n",
            "1.6936285495758057\n",
            "782\n",
            "1.7011377811431885\n",
            "783\n",
            "1.7150726318359375\n",
            "784\n",
            "1.7525622844696045\n",
            "785\n",
            "1.727072834968567\n",
            "786\n",
            "1.6856162548065186\n",
            "787\n",
            "1.7111525535583496\n",
            "788\n",
            "1.7514917850494385\n",
            "789\n",
            "1.7103898525238037\n",
            "790\n",
            "1.7268933057785034\n",
            "791\n",
            "1.6885305643081665\n",
            "792\n",
            "1.719223976135254\n",
            "793\n",
            "1.7544338703155518\n",
            "794\n",
            "1.7009589672088623\n",
            "795\n",
            "1.6963520050048828\n",
            "796\n",
            "1.7341880798339844\n",
            "797\n",
            "1.6819043159484863\n",
            "798\n",
            "1.678125023841858\n",
            "799\n",
            "1.6831402778625488\n",
            "800\n",
            "step: 800, train loss: 1.622, val loss: 1.826\n",
            "1.7100210189819336\n",
            "801\n",
            "1.6990145444869995\n",
            "802\n",
            "1.7201730012893677\n",
            "803\n",
            "1.6882555484771729\n",
            "804\n",
            "1.7103612422943115\n",
            "805\n",
            "1.6747490167617798\n",
            "806\n",
            "1.7446494102478027\n",
            "807\n",
            "1.7015210390090942\n",
            "808\n",
            "1.6943809986114502\n",
            "809\n",
            "1.6931545734405518\n",
            "810\n",
            "1.6999297142028809\n",
            "811\n",
            "1.6914457082748413\n",
            "812\n",
            "1.701180338859558\n",
            "813\n",
            "1.6959823369979858\n",
            "814\n",
            "1.7113696336746216\n",
            "815\n",
            "1.6932674646377563\n",
            "816\n",
            "1.6462602615356445\n",
            "817\n",
            "1.6457704305648804\n",
            "818\n",
            "1.6897552013397217\n",
            "819\n",
            "1.6945180892944336\n",
            "820\n",
            "1.6795482635498047\n",
            "821\n",
            "1.6611912250518799\n",
            "822\n",
            "1.6655197143554688\n",
            "823\n",
            "1.6236313581466675\n",
            "824\n",
            "1.7108705043792725\n",
            "825\n",
            "1.6936914920806885\n",
            "826\n",
            "1.6987407207489014\n",
            "827\n",
            "1.7257007360458374\n",
            "828\n",
            "1.6560550928115845\n",
            "829\n",
            "1.6846652030944824\n",
            "830\n",
            "1.7212963104248047\n",
            "831\n",
            "1.6485660076141357\n",
            "832\n",
            "1.6434825658798218\n",
            "833\n",
            "1.7243629693984985\n",
            "834\n",
            "1.6473839282989502\n",
            "835\n",
            "1.6771750450134277\n",
            "836\n",
            "1.678921103477478\n",
            "837\n",
            "1.6758625507354736\n",
            "838\n",
            "1.7076653242111206\n",
            "839\n",
            "1.656402826309204\n",
            "840\n",
            "1.7047125101089478\n",
            "841\n",
            "1.6288869380950928\n",
            "842\n",
            "1.7384380102157593\n",
            "843\n",
            "1.643794298171997\n",
            "844\n",
            "1.7149165868759155\n",
            "845\n",
            "1.6961987018585205\n",
            "846\n",
            "1.6715178489685059\n",
            "847\n",
            "1.6524653434753418\n",
            "848\n",
            "1.669039011001587\n",
            "849\n",
            "1.674930214881897\n",
            "850\n",
            "step: 850, train loss: 1.599, val loss: 1.812\n",
            "1.7003637552261353\n",
            "851\n",
            "1.6394599676132202\n",
            "852\n",
            "1.6614644527435303\n",
            "853\n",
            "1.6770908832550049\n",
            "854\n",
            "1.6401840448379517\n",
            "855\n",
            "1.705498218536377\n",
            "856\n",
            "1.6305091381072998\n",
            "857\n",
            "1.6753220558166504\n",
            "858\n",
            "1.6641722917556763\n",
            "859\n",
            "1.703676462173462\n",
            "860\n",
            "1.6339387893676758\n",
            "861\n",
            "1.6584172248840332\n",
            "862\n",
            "1.7486109733581543\n",
            "863\n",
            "1.6983251571655273\n",
            "864\n",
            "1.6550946235656738\n",
            "865\n",
            "1.6646039485931396\n",
            "866\n",
            "1.637364387512207\n",
            "867\n",
            "1.6976184844970703\n",
            "868\n",
            "1.6921095848083496\n",
            "869\n",
            "1.6683670282363892\n",
            "870\n",
            "1.6455047130584717\n",
            "871\n",
            "1.643813133239746\n",
            "872\n",
            "1.6523373126983643\n",
            "873\n",
            "1.6589643955230713\n",
            "874\n",
            "1.693515419960022\n",
            "875\n",
            "1.6408157348632812\n",
            "876\n",
            "1.6777329444885254\n",
            "877\n",
            "1.6688272953033447\n",
            "878\n",
            "1.6916186809539795\n",
            "879\n",
            "1.6201931238174438\n",
            "880\n",
            "1.6752328872680664\n",
            "881\n",
            "1.6260501146316528\n",
            "882\n",
            "1.6487407684326172\n",
            "883\n",
            "1.6229017972946167\n",
            "884\n",
            "1.6589891910552979\n",
            "885\n",
            "1.6915732622146606\n",
            "886\n",
            "1.6629881858825684\n",
            "887\n",
            "1.6471601724624634\n",
            "888\n",
            "1.6479289531707764\n",
            "889\n",
            "1.62908935546875\n",
            "890\n",
            "1.6225465536117554\n",
            "891\n",
            "1.617844581604004\n",
            "892\n",
            "1.6468381881713867\n",
            "893\n",
            "1.633683204650879\n",
            "894\n",
            "1.6329634189605713\n",
            "895\n",
            "1.6471946239471436\n",
            "896\n",
            "1.6541192531585693\n",
            "897\n",
            "1.63999605178833\n",
            "898\n",
            "1.6561198234558105\n",
            "899\n",
            "1.6654289960861206\n",
            "900\n",
            "step: 900, train loss: 1.566, val loss: 1.757\n",
            "1.6390694379806519\n",
            "901\n",
            "1.6559231281280518\n",
            "902\n",
            "1.6885972023010254\n",
            "903\n",
            "1.6331654787063599\n",
            "904\n",
            "1.6347992420196533\n",
            "905\n",
            "1.6557185649871826\n",
            "906\n",
            "1.6185917854309082\n",
            "907\n",
            "1.6654078960418701\n",
            "908\n",
            "1.6136219501495361\n",
            "909\n",
            "1.6873784065246582\n",
            "910\n",
            "1.6358636617660522\n",
            "911\n",
            "1.6610697507858276\n",
            "912\n",
            "1.6466495990753174\n",
            "913\n",
            "1.6693403720855713\n",
            "914\n",
            "1.709718942642212\n",
            "915\n",
            "1.6271628141403198\n",
            "916\n",
            "1.6493695974349976\n",
            "917\n",
            "1.6840088367462158\n",
            "918\n",
            "1.6659154891967773\n",
            "919\n",
            "1.673628807067871\n",
            "920\n",
            "1.6850907802581787\n",
            "921\n",
            "1.671345591545105\n",
            "922\n",
            "1.627439260482788\n",
            "923\n",
            "1.6148935556411743\n",
            "924\n",
            "1.6728355884552002\n",
            "925\n",
            "1.6731257438659668\n",
            "926\n",
            "1.6365807056427002\n",
            "927\n",
            "1.6874778270721436\n",
            "928\n",
            "1.6429686546325684\n",
            "929\n",
            "1.6603946685791016\n",
            "930\n",
            "1.6805506944656372\n",
            "931\n",
            "1.6279699802398682\n",
            "932\n",
            "1.6209385395050049\n",
            "933\n",
            "1.6882174015045166\n",
            "934\n",
            "1.6644582748413086\n",
            "935\n",
            "1.6538987159729004\n",
            "936\n",
            "1.6644806861877441\n",
            "937\n",
            "1.638829231262207\n",
            "938\n",
            "1.6339666843414307\n",
            "939\n",
            "1.633254051208496\n",
            "940\n",
            "1.5823174715042114\n",
            "941\n",
            "1.6972250938415527\n",
            "942\n",
            "1.66424560546875\n",
            "943\n",
            "1.6517243385314941\n",
            "944\n",
            "1.652569055557251\n",
            "945\n",
            "1.651707649230957\n",
            "946\n",
            "1.6391773223876953\n",
            "947\n",
            "1.6284847259521484\n",
            "948\n",
            "1.6807072162628174\n",
            "949\n",
            "1.6291261911392212\n",
            "950\n",
            "step: 950, train loss: 1.548, val loss: 1.778\n",
            "1.6228232383728027\n",
            "951\n",
            "1.635349988937378\n",
            "952\n",
            "1.6156845092773438\n",
            "953\n",
            "1.6433393955230713\n",
            "954\n",
            "1.6428279876708984\n",
            "955\n",
            "1.6283389329910278\n",
            "956\n",
            "1.6409987211227417\n",
            "957\n",
            "1.6901872158050537\n",
            "958\n",
            "1.6318614482879639\n",
            "959\n",
            "1.6321165561676025\n",
            "960\n",
            "1.5717668533325195\n",
            "961\n",
            "1.6611210107803345\n",
            "962\n",
            "1.6871657371520996\n",
            "963\n",
            "1.614325761795044\n",
            "964\n",
            "1.588232159614563\n",
            "965\n",
            "1.6296868324279785\n",
            "966\n",
            "1.6270766258239746\n",
            "967\n",
            "1.5999971628189087\n",
            "968\n",
            "1.676970362663269\n",
            "969\n",
            "1.6301213502883911\n",
            "970\n",
            "1.6046433448791504\n",
            "971\n",
            "1.6611449718475342\n",
            "972\n",
            "1.6610441207885742\n",
            "973\n",
            "1.6403014659881592\n",
            "974\n",
            "1.6552642583847046\n",
            "975\n",
            "1.6086761951446533\n",
            "976\n",
            "1.614201545715332\n",
            "977\n",
            "1.615356683731079\n",
            "978\n",
            "1.622077226638794\n",
            "979\n",
            "1.687452793121338\n",
            "980\n",
            "1.6197190284729004\n",
            "981\n",
            "1.638573169708252\n",
            "982\n",
            "1.663528561592102\n",
            "983\n",
            "1.6488573551177979\n",
            "984\n",
            "1.6002346277236938\n",
            "985\n",
            "1.565880537033081\n",
            "986\n",
            "1.6036663055419922\n",
            "987\n",
            "1.6465978622436523\n",
            "988\n",
            "1.6391849517822266\n",
            "989\n",
            "1.6053879261016846\n",
            "990\n",
            "1.574735403060913\n",
            "991\n",
            "1.6332411766052246\n",
            "992\n",
            "1.5934813022613525\n",
            "993\n",
            "1.6375683546066284\n",
            "994\n",
            "1.6245574951171875\n",
            "995\n",
            "1.6053022146224976\n",
            "996\n",
            "1.6207118034362793\n",
            "997\n",
            "1.603773593902588\n",
            "998\n",
            "1.6008260250091553\n",
            "999\n",
            "1.5845181941986084\n",
            "1000\n",
            "step: 1000, train loss: 1.522, val loss: 1.755\n",
            "1.588095784187317\n",
            "1001\n",
            "1.635846495628357\n",
            "1002\n",
            "1.6543378829956055\n",
            "1003\n",
            "1.6136837005615234\n",
            "1004\n",
            "1.6002283096313477\n",
            "1005\n",
            "1.6154978275299072\n",
            "1006\n",
            "1.6005597114562988\n",
            "1007\n",
            "1.6403768062591553\n",
            "1008\n",
            "1.595686435699463\n",
            "1009\n",
            "1.6393392086029053\n",
            "1010\n",
            "1.6350388526916504\n",
            "1011\n",
            "1.5853049755096436\n",
            "1012\n",
            "1.5979292392730713\n",
            "1013\n",
            "1.605942726135254\n",
            "1014\n",
            "1.5692960023880005\n",
            "1015\n",
            "1.6008740663528442\n",
            "1016\n",
            "1.6229956150054932\n",
            "1017\n",
            "1.5997662544250488\n",
            "1018\n",
            "1.5766873359680176\n",
            "1019\n",
            "1.6375081539154053\n",
            "1020\n",
            "1.621502161026001\n",
            "1021\n",
            "1.615485429763794\n",
            "1022\n",
            "1.611617088317871\n",
            "1023\n",
            "1.5912261009216309\n",
            "1024\n",
            "1.6270852088928223\n",
            "1025\n",
            "1.5782296657562256\n",
            "1026\n",
            "1.5921032428741455\n",
            "1027\n",
            "1.5889617204666138\n",
            "1028\n",
            "1.653329849243164\n",
            "1029\n",
            "1.6287262439727783\n",
            "1030\n",
            "1.645411491394043\n",
            "1031\n",
            "1.6122231483459473\n",
            "1032\n",
            "1.6133137941360474\n",
            "1033\n",
            "1.567124605178833\n",
            "1034\n",
            "1.6353719234466553\n",
            "1035\n",
            "1.6006325483322144\n",
            "1036\n",
            "1.5725412368774414\n",
            "1037\n",
            "1.6089863777160645\n",
            "1038\n",
            "1.6190733909606934\n",
            "1039\n",
            "1.5825334787368774\n",
            "1040\n",
            "1.6160271167755127\n",
            "1041\n",
            "1.608593225479126\n",
            "1042\n",
            "1.5661848783493042\n",
            "1043\n",
            "1.6105082035064697\n",
            "1044\n",
            "1.6615946292877197\n",
            "1045\n",
            "1.591573715209961\n",
            "1046\n",
            "1.7033662796020508\n",
            "1047\n",
            "1.5772991180419922\n",
            "1048\n",
            "1.5998995304107666\n",
            "1049\n",
            "1.616323471069336\n",
            "1050\n",
            "step: 1050, train loss: 1.511, val loss: 1.732\n",
            "1.6133798360824585\n",
            "1051\n",
            "1.6015135049819946\n",
            "1052\n",
            "1.6294116973876953\n",
            "1053\n",
            "1.570267915725708\n",
            "1054\n",
            "1.5745205879211426\n",
            "1055\n",
            "1.6110543012619019\n",
            "1056\n",
            "1.5347920656204224\n",
            "1057\n",
            "1.576301097869873\n",
            "1058\n",
            "1.6242507696151733\n",
            "1059\n",
            "1.6091105937957764\n",
            "1060\n",
            "1.6001286506652832\n",
            "1061\n",
            "1.5750080347061157\n",
            "1062\n",
            "1.5955255031585693\n",
            "1063\n",
            "1.59675931930542\n",
            "1064\n",
            "1.5736992359161377\n",
            "1065\n",
            "1.5850496292114258\n",
            "1066\n",
            "1.5824658870697021\n",
            "1067\n",
            "1.596230387687683\n",
            "1068\n",
            "1.5548467636108398\n",
            "1069\n",
            "1.6379039287567139\n",
            "1070\n",
            "1.6962271928787231\n",
            "1071\n",
            "1.594609022140503\n",
            "1072\n",
            "1.6142609119415283\n",
            "1073\n",
            "1.5704379081726074\n",
            "1074\n",
            "1.5978630781173706\n",
            "1075\n",
            "1.5825715065002441\n",
            "1076\n",
            "1.5458312034606934\n",
            "1077\n",
            "1.600477933883667\n",
            "1078\n",
            "1.612213134765625\n",
            "1079\n",
            "1.5853469371795654\n",
            "1080\n",
            "1.5576636791229248\n",
            "1081\n",
            "1.5754096508026123\n",
            "1082\n",
            "1.6479244232177734\n",
            "1083\n",
            "1.6076467037200928\n",
            "1084\n",
            "1.5926218032836914\n",
            "1085\n",
            "1.5620893239974976\n",
            "1086\n",
            "1.5570621490478516\n",
            "1087\n",
            "1.6337863206863403\n",
            "1088\n",
            "1.5791575908660889\n",
            "1089\n",
            "1.5439794063568115\n",
            "1090\n",
            "1.581128716468811\n",
            "1091\n",
            "1.5935900211334229\n",
            "1092\n",
            "1.6477898359298706\n",
            "1093\n",
            "1.5732402801513672\n",
            "1094\n",
            "1.5833299160003662\n",
            "1095\n",
            "1.5633466243743896\n",
            "1096\n",
            "1.5225406885147095\n",
            "1097\n",
            "1.5551342964172363\n",
            "1098\n",
            "1.59983229637146\n",
            "1099\n",
            "1.5955344438552856\n",
            "1100\n",
            "step: 1100, train loss: 1.492, val loss: 1.700\n",
            "1.586057186126709\n",
            "1101\n",
            "1.5439653396606445\n",
            "1102\n",
            "1.5649365186691284\n",
            "1103\n",
            "1.5764366388320923\n",
            "1104\n",
            "1.6211066246032715\n",
            "1105\n",
            "1.5654205083847046\n",
            "1106\n",
            "1.5753040313720703\n",
            "1107\n",
            "1.5835598707199097\n",
            "1108\n",
            "1.6014635562896729\n",
            "1109\n",
            "1.5691540241241455\n",
            "1110\n",
            "1.606690526008606\n",
            "1111\n",
            "1.6035544872283936\n",
            "1112\n",
            "1.6040775775909424\n",
            "1113\n",
            "1.5773133039474487\n",
            "1114\n",
            "1.5638084411621094\n",
            "1115\n",
            "1.5858612060546875\n",
            "1116\n",
            "1.639487624168396\n",
            "1117\n",
            "1.5420976877212524\n",
            "1118\n",
            "1.5496572256088257\n",
            "1119\n",
            "1.606598138809204\n",
            "1120\n",
            "1.599780797958374\n",
            "1121\n",
            "1.5915272235870361\n",
            "1122\n",
            "1.5463788509368896\n",
            "1123\n",
            "1.5995864868164062\n",
            "1124\n",
            "1.567326307296753\n",
            "1125\n",
            "1.5679599046707153\n",
            "1126\n",
            "1.5584814548492432\n",
            "1127\n",
            "1.5461859703063965\n",
            "1128\n",
            "1.5454610586166382\n",
            "1129\n",
            "1.6329858303070068\n",
            "1130\n",
            "1.532069444656372\n",
            "1131\n",
            "1.5749104022979736\n",
            "1132\n",
            "1.5566487312316895\n",
            "1133\n",
            "1.6092791557312012\n",
            "1134\n",
            "1.5934624671936035\n",
            "1135\n",
            "1.5586230754852295\n",
            "1136\n",
            "1.5750714540481567\n",
            "1137\n",
            "1.6003162860870361\n",
            "1138\n",
            "1.5826239585876465\n",
            "1139\n",
            "1.5662562847137451\n",
            "1140\n",
            "1.5895732641220093\n",
            "1141\n",
            "1.6167216300964355\n",
            "1142\n",
            "1.5518265962600708\n",
            "1143\n",
            "1.526626467704773\n",
            "1144\n",
            "1.6069490909576416\n",
            "1145\n",
            "1.5634033679962158\n",
            "1146\n",
            "1.610372543334961\n",
            "1147\n",
            "1.5363805294036865\n",
            "1148\n",
            "1.5732152462005615\n",
            "1149\n",
            "1.593881368637085\n",
            "1150\n",
            "step: 1150, train loss: 1.471, val loss: 1.670\n",
            "1.594467043876648\n",
            "1151\n",
            "1.583695411682129\n",
            "1152\n",
            "1.6308996677398682\n",
            "1153\n",
            "1.556922197341919\n",
            "1154\n",
            "1.5461909770965576\n",
            "1155\n",
            "1.5599408149719238\n",
            "1156\n",
            "1.5265014171600342\n",
            "1157\n",
            "1.5941073894500732\n",
            "1158\n",
            "1.5639960765838623\n",
            "1159\n",
            "1.6158645153045654\n",
            "1160\n",
            "1.5485467910766602\n",
            "1161\n",
            "1.5730690956115723\n",
            "1162\n",
            "1.5470677614212036\n",
            "1163\n",
            "1.5670548677444458\n",
            "1164\n",
            "1.6128329038619995\n",
            "1165\n",
            "1.5841364860534668\n",
            "1166\n",
            "1.5244550704956055\n",
            "1167\n",
            "1.5747928619384766\n",
            "1168\n",
            "1.5416200160980225\n",
            "1169\n",
            "1.5713900327682495\n",
            "1170\n",
            "1.566516637802124\n",
            "1171\n",
            "1.5490273237228394\n",
            "1172\n",
            "1.57295560836792\n",
            "1173\n",
            "1.5392489433288574\n",
            "1174\n",
            "1.5505609512329102\n",
            "1175\n",
            "1.5640971660614014\n",
            "1176\n",
            "1.5401798486709595\n",
            "1177\n",
            "1.5248757600784302\n",
            "1178\n",
            "1.5988037586212158\n",
            "1179\n",
            "1.5482511520385742\n",
            "1180\n",
            "1.5766289234161377\n",
            "1181\n",
            "1.5269314050674438\n",
            "1182\n",
            "1.581681489944458\n",
            "1183\n",
            "1.5964593887329102\n",
            "1184\n",
            "1.5422253608703613\n",
            "1185\n",
            "1.5235376358032227\n",
            "1186\n",
            "1.5918962955474854\n",
            "1187\n",
            "1.5439951419830322\n",
            "1188\n",
            "1.5435469150543213\n",
            "1189\n",
            "1.5809799432754517\n",
            "1190\n",
            "1.4768702983856201\n",
            "1191\n",
            "1.5976543426513672\n",
            "1192\n",
            "1.539367914199829\n",
            "1193\n",
            "1.5395900011062622\n",
            "1194\n",
            "1.5698356628417969\n",
            "1195\n",
            "1.5185766220092773\n",
            "1196\n",
            "1.52439546585083\n",
            "1197\n",
            "1.5145692825317383\n",
            "1198\n",
            "1.5219357013702393\n",
            "1199\n",
            "1.5386383533477783\n",
            "1200\n",
            "step: 1200, train loss: 1.464, val loss: 1.724\n",
            "1.6191880702972412\n",
            "1201\n",
            "1.527777910232544\n",
            "1202\n",
            "1.5464756488800049\n",
            "1203\n",
            "1.5683696269989014\n",
            "1204\n",
            "1.5421440601348877\n",
            "1205\n",
            "1.5607422590255737\n",
            "1206\n",
            "1.5701141357421875\n",
            "1207\n",
            "1.535257339477539\n",
            "1208\n",
            "1.5622235536575317\n",
            "1209\n",
            "1.539860486984253\n",
            "1210\n",
            "1.4976383447647095\n",
            "1211\n",
            "1.549909234046936\n",
            "1212\n",
            "1.5678637027740479\n",
            "1213\n",
            "1.5469329357147217\n",
            "1214\n",
            "1.514278769493103\n",
            "1215\n",
            "1.5426526069641113\n",
            "1216\n",
            "1.6033406257629395\n",
            "1217\n",
            "1.5292410850524902\n",
            "1218\n",
            "1.5346124172210693\n",
            "1219\n",
            "1.5368086099624634\n",
            "1220\n",
            "1.5857658386230469\n",
            "1221\n",
            "1.5484528541564941\n",
            "1222\n",
            "1.5275166034698486\n",
            "1223\n",
            "1.5948960781097412\n",
            "1224\n",
            "1.5461746454238892\n",
            "1225\n",
            "1.5798389911651611\n",
            "1226\n",
            "1.5228668451309204\n",
            "1227\n",
            "1.5102956295013428\n",
            "1228\n",
            "1.5497560501098633\n",
            "1229\n",
            "1.5664615631103516\n",
            "1230\n",
            "1.539939284324646\n",
            "1231\n",
            "1.5394501686096191\n",
            "1232\n",
            "1.556061029434204\n",
            "1233\n",
            "1.5542864799499512\n",
            "1234\n",
            "1.529687762260437\n",
            "1235\n",
            "1.5826777219772339\n",
            "1236\n",
            "1.5135984420776367\n",
            "1237\n",
            "1.548816204071045\n",
            "1238\n",
            "1.584539771080017\n",
            "1239\n",
            "1.5861945152282715\n",
            "1240\n",
            "1.5937976837158203\n",
            "1241\n",
            "1.5434353351593018\n",
            "1242\n",
            "1.52829110622406\n",
            "1243\n",
            "1.514627456665039\n",
            "1244\n",
            "1.6007598638534546\n",
            "1245\n",
            "1.5413362979888916\n",
            "1246\n",
            "1.53368079662323\n",
            "1247\n",
            "1.550933599472046\n",
            "1248\n",
            "1.6106605529785156\n",
            "1249\n",
            "1.509597897529602\n",
            "1250\n",
            "step: 1250, train loss: 1.447, val loss: 1.693\n",
            "1.5483646392822266\n",
            "1251\n",
            "1.54032301902771\n",
            "1252\n",
            "1.5343000888824463\n",
            "1253\n",
            "1.5195159912109375\n",
            "1254\n",
            "1.5683071613311768\n",
            "1255\n",
            "1.5311007499694824\n",
            "1256\n",
            "1.54049551486969\n",
            "1257\n",
            "1.560056447982788\n",
            "1258\n",
            "1.5914174318313599\n",
            "1259\n",
            "1.5567328929901123\n",
            "1260\n",
            "1.5578465461730957\n",
            "1261\n",
            "1.5282721519470215\n",
            "1262\n",
            "1.5674147605895996\n",
            "1263\n",
            "1.5400259494781494\n",
            "1264\n",
            "1.5430011749267578\n",
            "1265\n",
            "1.5892267227172852\n",
            "1266\n",
            "1.5072062015533447\n",
            "1267\n",
            "1.576012134552002\n",
            "1268\n",
            "1.5077705383300781\n",
            "1269\n",
            "1.5195176601409912\n",
            "1270\n",
            "1.5379178524017334\n",
            "1271\n",
            "1.5752934217453003\n",
            "1272\n",
            "1.5238020420074463\n",
            "1273\n",
            "1.5909132957458496\n",
            "1274\n",
            "1.50886869430542\n",
            "1275\n",
            "1.5213619470596313\n",
            "1276\n",
            "1.5682313442230225\n",
            "1277\n",
            "1.513890266418457\n",
            "1278\n",
            "1.5587279796600342\n",
            "1279\n",
            "1.5186597108840942\n",
            "1280\n",
            "1.5381555557250977\n",
            "1281\n",
            "1.5463042259216309\n",
            "1282\n",
            "1.533387303352356\n",
            "1283\n",
            "1.514524221420288\n",
            "1284\n",
            "1.4886295795440674\n",
            "1285\n",
            "1.5158064365386963\n",
            "1286\n",
            "1.5314216613769531\n",
            "1287\n",
            "1.5001089572906494\n",
            "1288\n",
            "1.5336873531341553\n",
            "1289\n",
            "1.4691967964172363\n",
            "1290\n",
            "1.5396379232406616\n",
            "1291\n",
            "1.5389431715011597\n",
            "1292\n",
            "1.5195508003234863\n",
            "1293\n",
            "1.470693588256836\n",
            "1294\n",
            "1.5516399145126343\n",
            "1295\n",
            "1.5612281560897827\n",
            "1296\n",
            "1.5448185205459595\n",
            "1297\n",
            "1.526300311088562\n",
            "1298\n",
            "1.5279181003570557\n",
            "1299\n",
            "1.5488818883895874\n",
            "1300\n",
            "step: 1300, train loss: 1.430, val loss: 1.682\n",
            "1.4864022731781006\n",
            "1301\n",
            "1.541823148727417\n",
            "1302\n",
            "1.5084826946258545\n",
            "1303\n",
            "1.5128347873687744\n",
            "1304\n",
            "1.5340553522109985\n",
            "1305\n",
            "1.5694208145141602\n",
            "1306\n",
            "1.5397224426269531\n",
            "1307\n",
            "1.5400551557540894\n",
            "1308\n",
            "1.5583494901657104\n",
            "1309\n",
            "1.4816862344741821\n",
            "1310\n",
            "1.5354986190795898\n",
            "1311\n",
            "1.5681500434875488\n",
            "1312\n",
            "1.544198989868164\n",
            "1313\n",
            "1.4862456321716309\n",
            "1314\n",
            "1.5624481439590454\n",
            "1315\n",
            "1.4861674308776855\n",
            "1316\n",
            "1.510955810546875\n",
            "1317\n",
            "1.5318387746810913\n",
            "1318\n",
            "1.478569746017456\n",
            "1319\n",
            "1.484104037284851\n",
            "1320\n",
            "1.5534372329711914\n",
            "1321\n",
            "1.531877875328064\n",
            "1322\n",
            "1.52066969871521\n",
            "1323\n",
            "1.5238245725631714\n",
            "1324\n",
            "1.5136170387268066\n",
            "1325\n",
            "1.5550322532653809\n",
            "1326\n",
            "1.5153026580810547\n",
            "1327\n",
            "1.5104644298553467\n",
            "1328\n",
            "1.497969388961792\n",
            "1329\n",
            "1.5186409950256348\n",
            "1330\n",
            "1.530439019203186\n",
            "1331\n",
            "1.5015339851379395\n",
            "1332\n",
            "1.569092035293579\n",
            "1333\n",
            "1.504884123802185\n",
            "1334\n",
            "1.5143802165985107\n",
            "1335\n",
            "1.487391710281372\n",
            "1336\n",
            "1.4803171157836914\n",
            "1337\n",
            "1.4697916507720947\n",
            "1338\n",
            "1.5179367065429688\n",
            "1339\n",
            "1.4723682403564453\n",
            "1340\n",
            "1.501596450805664\n",
            "1341\n",
            "1.5242313146591187\n",
            "1342\n",
            "1.5605909824371338\n",
            "1343\n",
            "1.4987437725067139\n",
            "1344\n",
            "1.511562705039978\n",
            "1345\n",
            "1.454820990562439\n",
            "1346\n",
            "1.5045366287231445\n",
            "1347\n",
            "1.4911919832229614\n",
            "1348\n",
            "1.4890960454940796\n",
            "1349\n",
            "1.454127311706543\n",
            "1350\n",
            "step: 1350, train loss: 1.423, val loss: 1.674\n",
            "1.507849931716919\n",
            "1351\n",
            "1.540456771850586\n",
            "1352\n",
            "1.5103123188018799\n",
            "1353\n",
            "1.4937034845352173\n",
            "1354\n",
            "1.5102667808532715\n",
            "1355\n",
            "1.499738335609436\n",
            "1356\n",
            "1.5516859292984009\n",
            "1357\n",
            "1.5245301723480225\n",
            "1358\n",
            "1.5210857391357422\n",
            "1359\n",
            "1.4556114673614502\n",
            "1360\n",
            "1.5759460926055908\n",
            "1361\n",
            "1.5290758609771729\n",
            "1362\n",
            "1.500519037246704\n",
            "1363\n",
            "1.5063328742980957\n",
            "1364\n",
            "1.479642391204834\n",
            "1365\n",
            "1.5109988451004028\n",
            "1366\n",
            "1.5363318920135498\n",
            "1367\n",
            "1.5462746620178223\n",
            "1368\n",
            "1.5343220233917236\n",
            "1369\n",
            "1.5579766035079956\n",
            "1370\n",
            "1.5563108921051025\n",
            "1371\n",
            "1.538390874862671\n",
            "1372\n",
            "1.4921389818191528\n",
            "1373\n",
            "1.5152000188827515\n",
            "1374\n",
            "1.531493902206421\n",
            "1375\n",
            "1.5898152589797974\n",
            "1376\n",
            "1.4846020936965942\n",
            "1377\n",
            "1.5095504522323608\n",
            "1378\n",
            "1.5589752197265625\n",
            "1379\n",
            "1.5046942234039307\n",
            "1380\n",
            "1.5099992752075195\n",
            "1381\n",
            "1.5395557880401611\n",
            "1382\n",
            "1.4935333728790283\n",
            "1383\n",
            "1.502776861190796\n",
            "1384\n",
            "1.4840019941329956\n",
            "1385\n",
            "1.4563530683517456\n",
            "1386\n",
            "1.5055797100067139\n",
            "1387\n",
            "1.520291805267334\n",
            "1388\n",
            "1.522676706314087\n",
            "1389\n",
            "1.4892122745513916\n",
            "1390\n",
            "1.4990872144699097\n",
            "1391\n",
            "1.4959239959716797\n",
            "1392\n",
            "1.4723448753356934\n",
            "1393\n",
            "1.5075047016143799\n",
            "1394\n",
            "1.4801921844482422\n",
            "1395\n",
            "1.485877513885498\n",
            "1396\n",
            "1.4683151245117188\n",
            "1397\n",
            "1.4977502822875977\n",
            "1398\n",
            "1.4941861629486084\n",
            "1399\n",
            "1.5176244974136353\n",
            "1400\n",
            "step: 1400, train loss: 1.410, val loss: 1.688\n",
            "1.527285099029541\n",
            "1401\n",
            "1.4853016138076782\n",
            "1402\n",
            "1.5229036808013916\n",
            "1403\n",
            "1.4784141778945923\n",
            "1404\n",
            "1.4888763427734375\n",
            "1405\n",
            "1.4432094097137451\n",
            "1406\n",
            "1.4784637689590454\n",
            "1407\n",
            "1.4712010622024536\n",
            "1408\n",
            "1.5176424980163574\n",
            "1409\n",
            "1.4506199359893799\n",
            "1410\n",
            "1.4916621446609497\n",
            "1411\n",
            "1.4768872261047363\n",
            "1412\n",
            "1.4976825714111328\n",
            "1413\n",
            "1.52543044090271\n",
            "1414\n",
            "1.5183310508728027\n",
            "1415\n",
            "1.5256216526031494\n",
            "1416\n",
            "1.4890273809432983\n",
            "1417\n",
            "1.4968476295471191\n",
            "1418\n",
            "1.4931524991989136\n",
            "1419\n",
            "1.4868115186691284\n",
            "1420\n",
            "1.5623548030853271\n",
            "1421\n",
            "1.441877841949463\n",
            "1422\n",
            "1.4466156959533691\n",
            "1423\n",
            "1.475684404373169\n",
            "1424\n",
            "1.5113306045532227\n",
            "1425\n",
            "1.4890974760055542\n",
            "1426\n",
            "1.5221370458602905\n",
            "1427\n",
            "1.5186692476272583\n",
            "1428\n",
            "1.4652419090270996\n",
            "1429\n",
            "1.501265525817871\n",
            "1430\n",
            "1.5366735458374023\n",
            "1431\n",
            "1.4959564208984375\n",
            "1432\n",
            "1.4827802181243896\n",
            "1433\n",
            "1.5097386837005615\n",
            "1434\n",
            "1.4955419301986694\n",
            "1435\n",
            "1.50099778175354\n",
            "1436\n",
            "1.4944154024124146\n",
            "1437\n",
            "1.5334389209747314\n",
            "1438\n",
            "1.4939521551132202\n",
            "1439\n",
            "1.4430656433105469\n",
            "1440\n",
            "1.4909117221832275\n",
            "1441\n",
            "1.4807820320129395\n",
            "1442\n",
            "1.5059539079666138\n",
            "1443\n",
            "1.4527275562286377\n",
            "1444\n",
            "1.5132689476013184\n",
            "1445\n",
            "1.4922688007354736\n",
            "1446\n",
            "1.4834680557250977\n",
            "1447\n",
            "1.5354719161987305\n",
            "1448\n",
            "1.4295965433120728\n",
            "1449\n",
            "1.4868671894073486\n",
            "1450\n",
            "step: 1450, train loss: 1.391, val loss: 1.672\n",
            "1.512718915939331\n",
            "1451\n",
            "1.5358457565307617\n",
            "1452\n",
            "1.5127348899841309\n",
            "1453\n",
            "1.5296635627746582\n",
            "1454\n",
            "1.509484052658081\n",
            "1455\n",
            "1.5212323665618896\n",
            "1456\n",
            "1.491967797279358\n",
            "1457\n",
            "1.4999899864196777\n",
            "1458\n",
            "1.5097906589508057\n",
            "1459\n",
            "1.4846861362457275\n",
            "1460\n",
            "1.4858967065811157\n",
            "1461\n",
            "1.4932801723480225\n",
            "1462\n",
            "1.456770658493042\n",
            "1463\n",
            "1.4505494832992554\n",
            "1464\n",
            "1.4478731155395508\n",
            "1465\n",
            "1.4854607582092285\n",
            "1466\n",
            "1.4746332168579102\n",
            "1467\n",
            "1.4724197387695312\n",
            "1468\n",
            "1.4868308305740356\n",
            "1469\n",
            "1.4807393550872803\n",
            "1470\n",
            "1.4831527471542358\n",
            "1471\n",
            "1.4549648761749268\n",
            "1472\n",
            "1.412412405014038\n",
            "1473\n",
            "1.5030659437179565\n",
            "1474\n",
            "1.497476577758789\n",
            "1475\n",
            "1.5183566808700562\n",
            "1476\n",
            "1.5248397588729858\n",
            "1477\n",
            "1.456700325012207\n",
            "1478\n",
            "1.5127454996109009\n",
            "1479\n",
            "1.565065860748291\n",
            "1480\n",
            "1.474899172782898\n",
            "1481\n",
            "1.4555505514144897\n",
            "1482\n",
            "1.4771064519882202\n",
            "1483\n",
            "1.540880799293518\n",
            "1484\n",
            "1.467314600944519\n",
            "1485\n",
            "1.4702657461166382\n",
            "1486\n",
            "1.4613057374954224\n",
            "1487\n",
            "1.453042984008789\n",
            "1488\n",
            "1.4869544506072998\n",
            "1489\n",
            "1.4582946300506592\n",
            "1490\n",
            "1.4995957612991333\n",
            "1491\n",
            "1.5172336101531982\n",
            "1492\n",
            "1.4835867881774902\n",
            "1493\n",
            "1.4941108226776123\n",
            "1494\n",
            "1.4440553188323975\n",
            "1495\n",
            "1.4129657745361328\n",
            "1496\n",
            "1.4690651893615723\n",
            "1497\n",
            "1.4868841171264648\n",
            "1498\n",
            "1.447953224182129\n",
            "1499\n",
            "1.482908844947815\n",
            "1500\n",
            "step: 1500, train loss: 1.384, val loss: 1.639\n",
            "1.4468226432800293\n",
            "1501\n",
            "1.468799352645874\n",
            "1502\n",
            "1.4812321662902832\n",
            "1503\n",
            "1.4900882244110107\n",
            "1504\n",
            "1.4896222352981567\n",
            "1505\n",
            "1.4993534088134766\n",
            "1506\n",
            "1.4702427387237549\n",
            "1507\n",
            "1.4900009632110596\n",
            "1508\n",
            "1.510232925415039\n",
            "1509\n",
            "1.4512808322906494\n",
            "1510\n",
            "1.5359916687011719\n",
            "1511\n",
            "1.499781847000122\n",
            "1512\n",
            "1.4743841886520386\n",
            "1513\n",
            "1.4659490585327148\n",
            "1514\n",
            "1.455609917640686\n",
            "1515\n",
            "1.4780858755111694\n",
            "1516\n",
            "1.5285446643829346\n",
            "1517\n",
            "1.4646515846252441\n",
            "1518\n",
            "1.4253435134887695\n",
            "1519\n",
            "1.508935809135437\n",
            "1520\n",
            "1.4569764137268066\n",
            "1521\n",
            "1.5047721862792969\n",
            "1522\n",
            "1.4558147192001343\n",
            "1523\n",
            "1.547218680381775\n",
            "1524\n",
            "1.4599056243896484\n",
            "1525\n",
            "1.4428900480270386\n",
            "1526\n",
            "1.44034743309021\n",
            "1527\n",
            "1.469618558883667\n",
            "1528\n",
            "1.4807400703430176\n",
            "1529\n",
            "1.471505880355835\n",
            "1530\n",
            "1.4160568714141846\n",
            "1531\n",
            "1.4619338512420654\n",
            "1532\n",
            "1.4856609106063843\n",
            "1533\n",
            "1.4508957862854004\n",
            "1534\n",
            "1.5290307998657227\n",
            "1535\n",
            "1.4754297733306885\n",
            "1536\n",
            "1.4698609113693237\n",
            "1537\n",
            "1.4541547298431396\n",
            "1538\n",
            "1.4852732419967651\n",
            "1539\n",
            "1.4922983646392822\n",
            "1540\n",
            "1.4839739799499512\n",
            "1541\n",
            "1.4850552082061768\n",
            "1542\n",
            "1.5268547534942627\n",
            "1543\n",
            "1.4890657663345337\n",
            "1544\n",
            "1.5028678178787231\n",
            "1545\n",
            "1.448131799697876\n",
            "1546\n",
            "1.449326992034912\n",
            "1547\n",
            "1.4413716793060303\n",
            "1548\n",
            "1.4496172666549683\n",
            "1549\n",
            "1.4963338375091553\n",
            "1550\n",
            "step: 1550, train loss: 1.379, val loss: 1.648\n",
            "1.481049656867981\n",
            "1551\n",
            "1.4589860439300537\n",
            "1552\n",
            "1.4636547565460205\n",
            "1553\n",
            "1.499577522277832\n",
            "1554\n",
            "1.500666856765747\n",
            "1555\n",
            "1.507500410079956\n",
            "1556\n",
            "1.434677243232727\n",
            "1557\n",
            "1.4118033647537231\n",
            "1558\n",
            "1.4485467672348022\n",
            "1559\n",
            "1.4736459255218506\n",
            "1560\n",
            "1.4540570974349976\n",
            "1561\n",
            "1.4844183921813965\n",
            "1562\n",
            "1.4787096977233887\n",
            "1563\n",
            "1.4364748001098633\n",
            "1564\n",
            "1.499245285987854\n",
            "1565\n",
            "1.4431425333023071\n",
            "1566\n",
            "1.4420430660247803\n",
            "1567\n",
            "1.4752936363220215\n",
            "1568\n",
            "1.4971247911453247\n",
            "1569\n",
            "1.4478168487548828\n",
            "1570\n",
            "1.5019577741622925\n",
            "1571\n",
            "1.4741073846817017\n",
            "1572\n",
            "1.4555110931396484\n",
            "1573\n",
            "1.4511051177978516\n",
            "1574\n",
            "1.443442702293396\n",
            "1575\n",
            "1.4508640766143799\n",
            "1576\n",
            "1.4478325843811035\n",
            "1577\n",
            "1.484233021736145\n",
            "1578\n",
            "1.4758658409118652\n",
            "1579\n",
            "1.4574114084243774\n",
            "1580\n",
            "1.4645178318023682\n",
            "1581\n",
            "1.4509742259979248\n",
            "1582\n",
            "1.4426000118255615\n",
            "1583\n",
            "1.498845100402832\n",
            "1584\n",
            "1.419468879699707\n",
            "1585\n",
            "1.4790892601013184\n",
            "1586\n",
            "1.5242400169372559\n",
            "1587\n",
            "1.492600440979004\n",
            "1588\n",
            "1.426771640777588\n",
            "1589\n",
            "1.437988042831421\n",
            "1590\n",
            "1.4291186332702637\n",
            "1591\n",
            "1.4740662574768066\n",
            "1592\n",
            "1.4802360534667969\n",
            "1593\n",
            "1.4173510074615479\n",
            "1594\n",
            "1.5099012851715088\n",
            "1595\n",
            "1.434689998626709\n",
            "1596\n",
            "1.4776829481124878\n",
            "1597\n",
            "1.3985486030578613\n",
            "1598\n",
            "1.4432640075683594\n",
            "1599\n",
            "1.4626003503799438\n",
            "1600\n",
            "step: 1600, train loss: 1.363, val loss: 1.643\n",
            "1.4580917358398438\n",
            "1601\n",
            "1.4433588981628418\n",
            "1602\n",
            "1.4747560024261475\n",
            "1603\n",
            "1.4468050003051758\n",
            "1604\n",
            "1.4337754249572754\n",
            "1605\n",
            "1.4049668312072754\n",
            "1606\n",
            "1.496685266494751\n",
            "1607\n",
            "1.4570796489715576\n",
            "1608\n",
            "1.4422166347503662\n",
            "1609\n",
            "1.5160404443740845\n",
            "1610\n",
            "1.4807841777801514\n",
            "1611\n",
            "1.423356294631958\n",
            "1612\n",
            "1.4745018482208252\n",
            "1613\n",
            "1.4511624574661255\n",
            "1614\n",
            "1.4714475870132446\n",
            "1615\n",
            "1.4512901306152344\n",
            "1616\n",
            "1.445159912109375\n",
            "1617\n",
            "1.475567102432251\n",
            "1618\n",
            "1.4715906381607056\n",
            "1619\n",
            "1.4738194942474365\n",
            "1620\n",
            "1.4407145977020264\n",
            "1621\n",
            "1.45645010471344\n",
            "1622\n",
            "1.4088958501815796\n",
            "1623\n",
            "1.4278303384780884\n",
            "1624\n",
            "1.4299654960632324\n",
            "1625\n",
            "1.46022367477417\n",
            "1626\n",
            "1.4416606426239014\n",
            "1627\n",
            "1.3844441175460815\n",
            "1628\n",
            "1.459815502166748\n",
            "1629\n",
            "1.476431131362915\n",
            "1630\n",
            "1.4662262201309204\n",
            "1631\n",
            "1.4290751218795776\n",
            "1632\n",
            "1.4139659404754639\n",
            "1633\n",
            "1.4738928079605103\n",
            "1634\n",
            "1.47329580783844\n",
            "1635\n",
            "1.4786701202392578\n",
            "1636\n",
            "1.4509599208831787\n",
            "1637\n",
            "1.4933207035064697\n",
            "1638\n",
            "1.4309484958648682\n",
            "1639\n",
            "1.4854917526245117\n",
            "1640\n",
            "1.4457905292510986\n",
            "1641\n",
            "1.438754677772522\n",
            "1642\n",
            "1.451345443725586\n",
            "1643\n",
            "1.4227607250213623\n",
            "1644\n",
            "1.3973963260650635\n",
            "1645\n",
            "1.4664430618286133\n",
            "1646\n",
            "1.4994237422943115\n",
            "1647\n",
            "1.450268268585205\n",
            "1648\n",
            "1.4598194360733032\n",
            "1649\n",
            "1.4643456935882568\n",
            "1650\n",
            "step: 1650, train loss: 1.352, val loss: 1.629\n",
            "1.4600112438201904\n",
            "1651\n",
            "1.4805867671966553\n",
            "1652\n",
            "1.4757591485977173\n",
            "1653\n",
            "1.4651157855987549\n",
            "1654\n",
            "1.4360713958740234\n",
            "1655\n",
            "1.437357783317566\n",
            "1656\n",
            "1.4722414016723633\n",
            "1657\n",
            "1.4443669319152832\n",
            "1658\n",
            "1.4666979312896729\n",
            "1659\n",
            "1.4542696475982666\n",
            "1660\n",
            "1.490391731262207\n",
            "1661\n",
            "1.4692926406860352\n",
            "1662\n",
            "1.4528273344039917\n",
            "1663\n",
            "1.4575870037078857\n",
            "1664\n",
            "1.451027274131775\n",
            "1665\n",
            "1.457801103591919\n",
            "1666\n",
            "1.4593874216079712\n",
            "1667\n",
            "1.422156810760498\n",
            "1668\n",
            "1.4540352821350098\n",
            "1669\n",
            "1.478195071220398\n",
            "1670\n",
            "1.4414725303649902\n",
            "1671\n",
            "1.441080927848816\n",
            "1672\n",
            "1.4442473649978638\n",
            "1673\n",
            "1.4406780004501343\n",
            "1674\n",
            "1.4840450286865234\n",
            "1675\n",
            "1.4523365497589111\n",
            "1676\n",
            "1.4282227754592896\n",
            "1677\n",
            "1.4604363441467285\n",
            "1678\n",
            "1.4428865909576416\n",
            "1679\n",
            "1.4464449882507324\n",
            "1680\n",
            "1.4466211795806885\n",
            "1681\n",
            "1.49955415725708\n",
            "1682\n",
            "1.418764352798462\n",
            "1683\n",
            "1.413849115371704\n",
            "1684\n",
            "1.4518866539001465\n",
            "1685\n",
            "1.4431705474853516\n",
            "1686\n",
            "1.4852397441864014\n",
            "1687\n",
            "1.4407488107681274\n",
            "1688\n",
            "1.4321411848068237\n",
            "1689\n",
            "1.4399524927139282\n",
            "1690\n",
            "1.4576562643051147\n",
            "1691\n",
            "1.4360566139221191\n",
            "1692\n",
            "1.4286236763000488\n",
            "1693\n",
            "1.4333935976028442\n",
            "1694\n",
            "1.4393529891967773\n",
            "1695\n",
            "1.4759045839309692\n",
            "1696\n",
            "1.4475229978561401\n",
            "1697\n",
            "1.478045105934143\n",
            "1698\n",
            "1.4120185375213623\n",
            "1699\n",
            "1.4104914665222168\n",
            "1700\n",
            "step: 1700, train loss: 1.348, val loss: 1.636\n",
            "1.4105026721954346\n",
            "1701\n",
            "1.4067232608795166\n",
            "1702\n",
            "1.4527018070220947\n",
            "1703\n",
            "1.4379801750183105\n",
            "1704\n",
            "1.4547088146209717\n",
            "1705\n",
            "1.466883897781372\n",
            "1706\n",
            "1.4729814529418945\n",
            "1707\n",
            "1.4866304397583008\n",
            "1708\n",
            "1.4591503143310547\n",
            "1709\n",
            "1.4767768383026123\n",
            "1710\n",
            "1.4717845916748047\n",
            "1711\n",
            "1.4708184003829956\n",
            "1712\n",
            "1.4269979000091553\n",
            "1713\n",
            "1.4174165725708008\n",
            "1714\n",
            "1.456713080406189\n",
            "1715\n",
            "1.4619216918945312\n",
            "1716\n",
            "1.4642560482025146\n",
            "1717\n",
            "1.5201218128204346\n",
            "1718\n",
            "1.4296796321868896\n",
            "1719\n",
            "1.4556970596313477\n",
            "1720\n",
            "1.4098877906799316\n",
            "1721\n",
            "1.4843437671661377\n",
            "1722\n",
            "1.4213837385177612\n",
            "1723\n",
            "1.3880277872085571\n",
            "1724\n",
            "1.4029685258865356\n",
            "1725\n",
            "1.4170446395874023\n",
            "1726\n",
            "1.406811237335205\n",
            "1727\n",
            "1.3903504610061646\n",
            "1728\n",
            "1.4404141902923584\n",
            "1729\n",
            "1.472292423248291\n",
            "1730\n",
            "1.4504163265228271\n",
            "1731\n",
            "1.4458932876586914\n",
            "1732\n",
            "1.5018846988677979\n",
            "1733\n",
            "1.4211583137512207\n",
            "1734\n",
            "1.4246232509613037\n",
            "1735\n",
            "1.4437485933303833\n",
            "1736\n",
            "1.4727437496185303\n",
            "1737\n",
            "1.4590049982070923\n",
            "1738\n",
            "1.418064832687378\n",
            "1739\n",
            "1.3741390705108643\n",
            "1740\n",
            "1.4100677967071533\n",
            "1741\n",
            "1.4008333683013916\n",
            "1742\n",
            "1.4277832508087158\n",
            "1743\n",
            "1.430034875869751\n",
            "1744\n",
            "1.464140772819519\n",
            "1745\n",
            "1.3959579467773438\n",
            "1746\n",
            "1.4118494987487793\n",
            "1747\n",
            "1.4225096702575684\n",
            "1748\n",
            "1.4426254034042358\n",
            "1749\n",
            "1.409454107284546\n",
            "1750\n",
            "step: 1750, train loss: 1.340, val loss: 1.619\n",
            "1.400855302810669\n",
            "1751\n",
            "1.4695533514022827\n",
            "1752\n",
            "1.4101594686508179\n",
            "1753\n",
            "1.4501748085021973\n",
            "1754\n",
            "1.4644819498062134\n",
            "1755\n",
            "1.4232392311096191\n",
            "1756\n",
            "1.384963870048523\n",
            "1757\n",
            "1.4585490226745605\n",
            "1758\n",
            "1.4824209213256836\n",
            "1759\n",
            "1.4645569324493408\n",
            "1760\n",
            "1.460379719734192\n",
            "1761\n",
            "1.4429395198822021\n",
            "1762\n",
            "1.4078171253204346\n",
            "1763\n",
            "1.4399752616882324\n",
            "1764\n",
            "1.427736759185791\n",
            "1765\n",
            "1.4265985488891602\n",
            "1766\n",
            "1.4180994033813477\n",
            "1767\n",
            "1.4100542068481445\n",
            "1768\n",
            "1.4035558700561523\n",
            "1769\n",
            "1.4903364181518555\n",
            "1770\n",
            "1.4343085289001465\n",
            "1771\n",
            "1.4150192737579346\n",
            "1772\n",
            "1.4558393955230713\n",
            "1773\n",
            "1.4490773677825928\n",
            "1774\n",
            "1.452982783317566\n",
            "1775\n",
            "1.4289159774780273\n",
            "1776\n",
            "1.4851622581481934\n",
            "1777\n",
            "1.466702938079834\n",
            "1778\n",
            "1.437756061553955\n",
            "1779\n",
            "1.4276056289672852\n",
            "1780\n",
            "1.3608485460281372\n",
            "1781\n",
            "1.4140584468841553\n",
            "1782\n",
            "1.4533686637878418\n",
            "1783\n",
            "1.3901596069335938\n",
            "1784\n",
            "1.4015560150146484\n",
            "1785\n",
            "1.4105277061462402\n",
            "1786\n",
            "1.4159892797470093\n",
            "1787\n",
            "1.3737177848815918\n",
            "1788\n",
            "1.3894314765930176\n",
            "1789\n",
            "1.4220571517944336\n",
            "1790\n",
            "1.4569737911224365\n",
            "1791\n",
            "1.3828997611999512\n",
            "1792\n",
            "1.4269850254058838\n",
            "1793\n",
            "1.4179586172103882\n",
            "1794\n",
            "1.4299620389938354\n",
            "1795\n",
            "1.4168293476104736\n",
            "1796\n",
            "1.4259098768234253\n",
            "1797\n",
            "1.4365441799163818\n",
            "1798\n",
            "1.4044474363327026\n",
            "1799\n",
            "1.3963866233825684\n",
            "1800\n",
            "step: 1800, train loss: 1.328, val loss: 1.612\n",
            "1.440688133239746\n",
            "1801\n",
            "1.406029462814331\n",
            "1802\n",
            "1.4073635339736938\n",
            "1803\n",
            "1.448760986328125\n",
            "1804\n",
            "1.3874263763427734\n",
            "1805\n",
            "1.4422962665557861\n",
            "1806\n",
            "1.427635908126831\n",
            "1807\n",
            "1.4224951267242432\n",
            "1808\n",
            "1.405756950378418\n",
            "1809\n",
            "1.4112792015075684\n",
            "1810\n",
            "1.3897699117660522\n",
            "1811\n",
            "1.4210221767425537\n",
            "1812\n",
            "1.384847640991211\n",
            "1813\n",
            "1.4176843166351318\n",
            "1814\n",
            "1.4285621643066406\n",
            "1815\n",
            "1.466320514678955\n",
            "1816\n",
            "1.4315147399902344\n",
            "1817\n",
            "1.389958143234253\n",
            "1818\n",
            "1.3943679332733154\n",
            "1819\n",
            "1.4246724843978882\n",
            "1820\n",
            "1.4171364307403564\n",
            "1821\n",
            "1.3981802463531494\n",
            "1822\n",
            "1.395370364189148\n",
            "1823\n",
            "1.4360628128051758\n",
            "1824\n",
            "1.4239197969436646\n",
            "1825\n",
            "1.4554028511047363\n",
            "1826\n",
            "1.4298295974731445\n",
            "1827\n",
            "1.4084954261779785\n",
            "1828\n",
            "1.4594593048095703\n",
            "1829\n",
            "1.4247782230377197\n",
            "1830\n",
            "1.4639933109283447\n",
            "1831\n",
            "1.4375886917114258\n",
            "1832\n",
            "1.44154691696167\n",
            "1833\n",
            "1.4352123737335205\n",
            "1834\n",
            "1.4059653282165527\n",
            "1835\n",
            "1.4541441202163696\n",
            "1836\n",
            "1.4076111316680908\n",
            "1837\n",
            "1.4394073486328125\n",
            "1838\n",
            "1.3867647647857666\n",
            "1839\n",
            "1.4338099956512451\n",
            "1840\n",
            "1.3734935522079468\n",
            "1841\n",
            "1.4122185707092285\n",
            "1842\n",
            "1.35917067527771\n",
            "1843\n",
            "1.4111824035644531\n",
            "1844\n",
            "1.4156768321990967\n",
            "1845\n",
            "1.4193172454833984\n",
            "1846\n",
            "1.4017504453659058\n",
            "1847\n",
            "1.400872826576233\n",
            "1848\n",
            "1.4138174057006836\n",
            "1849\n",
            "1.38283109664917\n",
            "1850\n",
            "step: 1850, train loss: 1.323, val loss: 1.589\n",
            "1.3979263305664062\n",
            "1851\n",
            "1.440631628036499\n",
            "1852\n",
            "1.3901596069335938\n",
            "1853\n",
            "1.4148837327957153\n",
            "1854\n",
            "1.4274767637252808\n",
            "1855\n",
            "1.3940095901489258\n",
            "1856\n",
            "1.399984359741211\n",
            "1857\n",
            "1.448789119720459\n",
            "1858\n",
            "1.4058417081832886\n",
            "1859\n",
            "1.420925259590149\n",
            "1860\n",
            "1.4269673824310303\n",
            "1861\n",
            "1.4060393571853638\n",
            "1862\n",
            "1.4119389057159424\n",
            "1863\n",
            "1.4184491634368896\n",
            "1864\n",
            "1.4384617805480957\n",
            "1865\n",
            "1.4256603717803955\n",
            "1866\n",
            "1.3846230506896973\n",
            "1867\n",
            "1.3911057710647583\n",
            "1868\n",
            "1.4347866773605347\n",
            "1869\n",
            "1.3861795663833618\n",
            "1870\n",
            "1.371260404586792\n",
            "1871\n",
            "1.4329994916915894\n",
            "1872\n",
            "1.4223066568374634\n",
            "1873\n",
            "1.3865545988082886\n",
            "1874\n",
            "1.4296762943267822\n",
            "1875\n",
            "1.4162383079528809\n",
            "1876\n",
            "1.4132862091064453\n",
            "1877\n",
            "1.413547158241272\n",
            "1878\n",
            "1.3842058181762695\n",
            "1879\n",
            "1.4148633480072021\n",
            "1880\n",
            "1.3857241868972778\n",
            "1881\n",
            "1.4137802124023438\n",
            "1882\n",
            "1.4141247272491455\n",
            "1883\n",
            "1.3844281435012817\n",
            "1884\n",
            "1.440551996231079\n",
            "1885\n",
            "1.5131614208221436\n",
            "1886\n",
            "1.4067637920379639\n",
            "1887\n",
            "1.3869130611419678\n",
            "1888\n",
            "1.4012078046798706\n",
            "1889\n",
            "1.419851303100586\n",
            "1890\n",
            "1.3810943365097046\n",
            "1891\n",
            "1.4304633140563965\n",
            "1892\n",
            "1.3988471031188965\n",
            "1893\n",
            "1.3948967456817627\n",
            "1894\n",
            "1.4278593063354492\n",
            "1895\n",
            "1.4347612857818604\n",
            "1896\n",
            "1.4231823682785034\n",
            "1897\n",
            "1.4125659465789795\n",
            "1898\n",
            "1.4235343933105469\n",
            "1899\n",
            "1.4364122152328491\n",
            "1900\n",
            "step: 1900, train loss: 1.324, val loss: 1.583\n",
            "1.3933453559875488\n",
            "1901\n",
            "1.4107563495635986\n",
            "1902\n",
            "1.445831298828125\n",
            "1903\n",
            "1.3779659271240234\n",
            "1904\n",
            "1.3875882625579834\n",
            "1905\n",
            "1.334483027458191\n",
            "1906\n",
            "1.4379123449325562\n",
            "1907\n",
            "1.4165456295013428\n",
            "1908\n",
            "1.4008097648620605\n",
            "1909\n",
            "1.4123077392578125\n",
            "1910\n",
            "1.3814358711242676\n",
            "1911\n",
            "1.441314458847046\n",
            "1912\n",
            "1.5035139322280884\n",
            "1913\n",
            "1.3544440269470215\n",
            "1914\n",
            "1.423064947128296\n",
            "1915\n",
            "1.4121003150939941\n",
            "1916\n",
            "1.4057762622833252\n",
            "1917\n",
            "1.3626997470855713\n",
            "1918\n",
            "1.4310197830200195\n",
            "1919\n",
            "1.4169087409973145\n",
            "1920\n",
            "1.4134830236434937\n",
            "1921\n",
            "1.3657011985778809\n",
            "1922\n",
            "1.3979127407073975\n",
            "1923\n",
            "1.4099875688552856\n",
            "1924\n",
            "1.3901954889297485\n",
            "1925\n",
            "1.3849430084228516\n",
            "1926\n",
            "1.4361295700073242\n",
            "1927\n",
            "1.3931853771209717\n",
            "1928\n",
            "1.3795597553253174\n",
            "1929\n",
            "1.3875830173492432\n",
            "1930\n",
            "1.3584040403366089\n",
            "1931\n",
            "1.395024061203003\n",
            "1932\n",
            "1.425832986831665\n",
            "1933\n",
            "1.3784749507904053\n",
            "1934\n",
            "1.416394591331482\n",
            "1935\n",
            "1.4289549589157104\n",
            "1936\n",
            "1.3579235076904297\n",
            "1937\n",
            "1.456989049911499\n",
            "1938\n",
            "1.4134347438812256\n",
            "1939\n",
            "1.3887238502502441\n",
            "1940\n",
            "1.3682085275650024\n",
            "1941\n",
            "1.4172085523605347\n",
            "1942\n",
            "1.4710749387741089\n",
            "1943\n",
            "1.3393104076385498\n",
            "1944\n",
            "1.4110804796218872\n",
            "1945\n",
            "1.3791511058807373\n",
            "1946\n",
            "1.3894433975219727\n",
            "1947\n",
            "1.3781931400299072\n",
            "1948\n",
            "1.3746742010116577\n",
            "1949\n",
            "1.3679227828979492\n",
            "1950\n",
            "step: 1950, train loss: 1.309, val loss: 1.596\n",
            "1.3953371047973633\n",
            "1951\n",
            "1.4207357168197632\n",
            "1952\n",
            "1.3747529983520508\n",
            "1953\n",
            "1.3773062229156494\n",
            "1954\n",
            "1.4312303066253662\n",
            "1955\n",
            "1.3326225280761719\n",
            "1956\n",
            "1.4008554220199585\n",
            "1957\n",
            "1.3645055294036865\n",
            "1958\n",
            "1.421213150024414\n",
            "1959\n",
            "1.3821901082992554\n",
            "1960\n",
            "1.3893482685089111\n",
            "1961\n",
            "1.3844261169433594\n",
            "1962\n",
            "1.3948873281478882\n",
            "1963\n",
            "1.3657400608062744\n",
            "1964\n",
            "1.4032201766967773\n",
            "1965\n",
            "1.382122278213501\n",
            "1966\n",
            "1.4333961009979248\n",
            "1967\n",
            "1.38423490524292\n",
            "1968\n",
            "1.387169361114502\n",
            "1969\n",
            "1.3634161949157715\n",
            "1970\n",
            "1.3733594417572021\n",
            "1971\n",
            "1.3986003398895264\n",
            "1972\n",
            "1.4082679748535156\n",
            "1973\n",
            "1.418590784072876\n",
            "1974\n",
            "1.4200398921966553\n",
            "1975\n",
            "1.3604214191436768\n",
            "1976\n",
            "1.3964307308197021\n",
            "1977\n",
            "1.4359755516052246\n",
            "1978\n",
            "1.4306833744049072\n",
            "1979\n",
            "1.371456503868103\n",
            "1980\n",
            "1.4012337923049927\n",
            "1981\n",
            "1.421783447265625\n",
            "1982\n",
            "1.4669647216796875\n",
            "1983\n",
            "1.4477567672729492\n",
            "1984\n",
            "1.3911937475204468\n",
            "1985\n",
            "1.3918089866638184\n",
            "1986\n",
            "1.386458396911621\n",
            "1987\n",
            "1.406057357788086\n",
            "1988\n",
            "1.449581265449524\n",
            "1989\n",
            "1.4943712949752808\n",
            "1990\n",
            "1.4284887313842773\n",
            "1991\n",
            "1.3833765983581543\n",
            "1992\n",
            "1.3983850479125977\n",
            "1993\n",
            "1.368819236755371\n",
            "1994\n",
            "1.3828058242797852\n",
            "1995\n",
            "1.447009801864624\n",
            "1996\n",
            "1.3737095594406128\n",
            "1997\n",
            "1.3991665840148926\n",
            "1998\n",
            "1.38033127784729\n",
            "1999\n",
            "1.381885290145874\n",
            "2000\n",
            "step: 2000, train loss: 1.301, val loss: 1.593\n",
            "1.3664875030517578\n",
            "2001\n",
            "1.3798202276229858\n",
            "2002\n",
            "1.4502232074737549\n",
            "2003\n",
            "1.4019479751586914\n",
            "2004\n",
            "1.3502579927444458\n",
            "2005\n",
            "1.456538438796997\n",
            "2006\n",
            "1.4137381315231323\n",
            "2007\n",
            "1.4156293869018555\n",
            "2008\n",
            "1.385560154914856\n",
            "2009\n",
            "1.4469091892242432\n",
            "2010\n",
            "1.4399863481521606\n",
            "2011\n",
            "1.392814040184021\n",
            "2012\n",
            "1.3413515090942383\n",
            "2013\n",
            "1.4113540649414062\n",
            "2014\n",
            "1.4251811504364014\n",
            "2015\n",
            "1.3943121433258057\n",
            "2016\n",
            "1.3746616840362549\n",
            "2017\n",
            "1.3762691020965576\n",
            "2018\n",
            "1.426457405090332\n",
            "2019\n",
            "1.4047858715057373\n",
            "2020\n",
            "1.3988754749298096\n",
            "2021\n",
            "1.392484188079834\n",
            "2022\n",
            "1.3732680082321167\n",
            "2023\n",
            "1.410463809967041\n",
            "2024\n",
            "1.3773820400238037\n",
            "2025\n",
            "1.3685643672943115\n",
            "2026\n",
            "1.369205355644226\n",
            "2027\n",
            "1.4196478128433228\n",
            "2028\n",
            "1.3920656442642212\n",
            "2029\n",
            "1.3970128297805786\n",
            "2030\n",
            "1.3840410709381104\n",
            "2031\n",
            "1.387455940246582\n",
            "2032\n",
            "1.4342968463897705\n",
            "2033\n",
            "1.3976798057556152\n",
            "2034\n",
            "1.4024603366851807\n",
            "2035\n",
            "1.3591138124465942\n",
            "2036\n",
            "1.3415374755859375\n",
            "2037\n",
            "1.4140325784683228\n",
            "2038\n",
            "1.382112979888916\n",
            "2039\n",
            "1.4184911251068115\n",
            "2040\n",
            "1.4173370599746704\n",
            "2041\n",
            "1.3752388954162598\n",
            "2042\n",
            "1.3358471393585205\n",
            "2043\n",
            "1.419827938079834\n",
            "2044\n",
            "1.4013144969940186\n",
            "2045\n",
            "1.4367462396621704\n",
            "2046\n",
            "1.3642840385437012\n",
            "2047\n",
            "1.4575245380401611\n",
            "2048\n",
            "1.395167589187622\n",
            "2049\n",
            "1.3977348804473877\n",
            "2050\n",
            "step: 2050, train loss: 1.289, val loss: 1.582\n",
            "1.396997094154358\n",
            "2051\n",
            "1.408657431602478\n",
            "2052\n",
            "1.4048997163772583\n",
            "2053\n",
            "1.362235188484192\n",
            "2054\n",
            "1.361337423324585\n",
            "2055\n",
            "1.3676674365997314\n",
            "2056\n",
            "1.3767189979553223\n",
            "2057\n",
            "1.4060425758361816\n",
            "2058\n",
            "1.430039882659912\n",
            "2059\n",
            "1.433968424797058\n",
            "2060\n",
            "1.4086904525756836\n",
            "2061\n",
            "1.3863115310668945\n",
            "2062\n",
            "1.3810086250305176\n",
            "2063\n",
            "1.42581045627594\n",
            "2064\n",
            "1.432271957397461\n",
            "2065\n",
            "1.3996816873550415\n",
            "2066\n",
            "1.3872356414794922\n",
            "2067\n",
            "1.3774230480194092\n",
            "2068\n",
            "1.3768596649169922\n",
            "2069\n",
            "1.4021412134170532\n",
            "2070\n",
            "1.3850867748260498\n",
            "2071\n",
            "1.3730802536010742\n",
            "2072\n",
            "1.3657104969024658\n",
            "2073\n",
            "1.3808610439300537\n",
            "2074\n",
            "1.4208366870880127\n",
            "2075\n",
            "1.3875046968460083\n",
            "2076\n",
            "1.331221342086792\n",
            "2077\n",
            "1.3731629848480225\n",
            "2078\n",
            "1.4026455879211426\n",
            "2079\n",
            "1.3103246688842773\n",
            "2080\n",
            "1.3942303657531738\n",
            "2081\n",
            "1.390833854675293\n",
            "2082\n",
            "1.4024403095245361\n",
            "2083\n",
            "1.3626165390014648\n",
            "2084\n",
            "1.4079889059066772\n",
            "2085\n",
            "1.348081111907959\n",
            "2086\n",
            "1.3845404386520386\n",
            "2087\n",
            "1.4159417152404785\n",
            "2088\n",
            "1.382507562637329\n",
            "2089\n",
            "1.3519484996795654\n",
            "2090\n",
            "1.3923200368881226\n",
            "2091\n",
            "1.3585896492004395\n",
            "2092\n",
            "1.3243772983551025\n",
            "2093\n",
            "1.372934103012085\n",
            "2094\n",
            "1.3844202756881714\n",
            "2095\n",
            "1.367492914199829\n",
            "2096\n",
            "1.3807027339935303\n",
            "2097\n",
            "1.36349618434906\n",
            "2098\n",
            "1.4015960693359375\n",
            "2099\n",
            "1.4159001111984253\n",
            "2100\n",
            "step: 2100, train loss: 1.276, val loss: 1.575\n",
            "1.4261257648468018\n",
            "2101\n",
            "1.3826777935028076\n",
            "2102\n",
            "1.3944711685180664\n",
            "2103\n",
            "1.408488154411316\n",
            "2104\n",
            "1.414762020111084\n",
            "2105\n",
            "1.384364366531372\n",
            "2106\n",
            "1.3677680492401123\n",
            "2107\n",
            "1.4358494281768799\n",
            "2108\n",
            "1.3761107921600342\n",
            "2109\n",
            "1.3375346660614014\n",
            "2110\n",
            "1.3868484497070312\n",
            "2111\n",
            "1.3740936517715454\n",
            "2112\n",
            "1.4281748533248901\n",
            "2113\n",
            "1.395457148551941\n",
            "2114\n",
            "1.3621437549591064\n",
            "2115\n",
            "1.4136548042297363\n",
            "2116\n",
            "1.3764349222183228\n",
            "2117\n",
            "1.394587516784668\n",
            "2118\n",
            "1.3679875135421753\n",
            "2119\n",
            "1.373526930809021\n",
            "2120\n",
            "1.3783774375915527\n",
            "2121\n",
            "1.3761000633239746\n",
            "2122\n",
            "1.4099012613296509\n",
            "2123\n",
            "1.3756232261657715\n",
            "2124\n",
            "1.3944380283355713\n",
            "2125\n",
            "1.3674156665802002\n",
            "2126\n",
            "1.4075520038604736\n",
            "2127\n",
            "1.3633568286895752\n",
            "2128\n",
            "1.3413019180297852\n",
            "2129\n",
            "1.4311879873275757\n",
            "2130\n",
            "1.3486573696136475\n",
            "2131\n",
            "1.3663690090179443\n",
            "2132\n",
            "1.4055345058441162\n",
            "2133\n",
            "1.311929702758789\n",
            "2134\n",
            "1.3988734483718872\n",
            "2135\n",
            "1.4219417572021484\n",
            "2136\n",
            "1.3349617719650269\n",
            "2137\n",
            "1.4007973670959473\n",
            "2138\n",
            "1.3441970348358154\n",
            "2139\n",
            "1.3783245086669922\n",
            "2140\n",
            "1.3841041326522827\n",
            "2141\n",
            "1.3795000314712524\n",
            "2142\n",
            "1.3488388061523438\n",
            "2143\n",
            "1.3843865394592285\n",
            "2144\n",
            "1.3865134716033936\n",
            "2145\n",
            "1.4416779279708862\n",
            "2146\n",
            "1.4051001071929932\n",
            "2147\n",
            "1.3859201669692993\n",
            "2148\n",
            "1.3339035511016846\n",
            "2149\n",
            "1.3832523822784424\n",
            "2150\n",
            "step: 2150, train loss: 1.276, val loss: 1.562\n",
            "1.3917452096939087\n",
            "2151\n",
            "1.3966861963272095\n",
            "2152\n",
            "1.3457738161087036\n",
            "2153\n",
            "1.3541500568389893\n",
            "2154\n",
            "1.396988034248352\n",
            "2155\n",
            "1.3846155405044556\n",
            "2156\n",
            "1.4025187492370605\n",
            "2157\n",
            "1.3970615863800049\n",
            "2158\n",
            "1.3488706350326538\n",
            "2159\n",
            "1.3670005798339844\n",
            "2160\n",
            "1.370788812637329\n",
            "2161\n",
            "1.4099684953689575\n",
            "2162\n",
            "1.457301139831543\n",
            "2163\n",
            "1.348364233970642\n",
            "2164\n",
            "1.3576200008392334\n",
            "2165\n",
            "1.3798773288726807\n",
            "2166\n",
            "1.3521654605865479\n",
            "2167\n",
            "1.3364064693450928\n",
            "2168\n",
            "1.3770191669464111\n",
            "2169\n",
            "1.419616460800171\n",
            "2170\n",
            "1.3623548746109009\n",
            "2171\n",
            "1.3504587411880493\n",
            "2172\n",
            "1.4053244590759277\n",
            "2173\n",
            "1.3181768655776978\n",
            "2174\n",
            "1.3704173564910889\n",
            "2175\n",
            "1.3445680141448975\n",
            "2176\n",
            "1.351125955581665\n",
            "2177\n",
            "1.3574494123458862\n",
            "2178\n",
            "1.320565938949585\n",
            "2179\n",
            "1.3434875011444092\n",
            "2180\n",
            "1.375868797302246\n",
            "2181\n",
            "1.4443507194519043\n",
            "2182\n",
            "1.3308173418045044\n",
            "2183\n",
            "1.41867196559906\n",
            "2184\n",
            "1.3534893989562988\n",
            "2185\n",
            "1.3514811992645264\n",
            "2186\n",
            "1.3694117069244385\n",
            "2187\n",
            "1.3821200132369995\n",
            "2188\n",
            "1.3374300003051758\n",
            "2189\n",
            "1.3656983375549316\n",
            "2190\n",
            "1.3813940286636353\n",
            "2191\n",
            "1.3400909900665283\n",
            "2192\n",
            "1.4051539897918701\n",
            "2193\n",
            "1.4052376747131348\n",
            "2194\n",
            "1.413433313369751\n",
            "2195\n",
            "1.3327596187591553\n",
            "2196\n",
            "1.419945478439331\n",
            "2197\n",
            "1.3826966285705566\n",
            "2198\n",
            "1.3762922286987305\n",
            "2199\n",
            "1.3352532386779785\n",
            "2200\n",
            "step: 2200, train loss: 1.271, val loss: 1.549\n",
            "1.3470277786254883\n",
            "2201\n",
            "1.380279779434204\n",
            "2202\n",
            "1.3750441074371338\n",
            "2203\n",
            "1.4020934104919434\n",
            "2204\n",
            "1.3783159255981445\n",
            "2205\n",
            "1.3421884775161743\n",
            "2206\n",
            "1.4012820720672607\n",
            "2207\n",
            "1.3637819290161133\n",
            "2208\n",
            "1.3487635850906372\n",
            "2209\n",
            "1.3121050596237183\n",
            "2210\n",
            "1.3525484800338745\n",
            "2211\n",
            "1.3374384641647339\n",
            "2212\n",
            "1.3252663612365723\n",
            "2213\n",
            "1.3110871315002441\n",
            "2214\n",
            "1.345611810684204\n",
            "2215\n",
            "1.3913946151733398\n",
            "2216\n",
            "1.3509621620178223\n",
            "2217\n",
            "1.304955244064331\n",
            "2218\n",
            "1.3830400705337524\n",
            "2219\n",
            "1.3413968086242676\n",
            "2220\n",
            "1.3570705652236938\n",
            "2221\n",
            "1.3816951513290405\n",
            "2222\n",
            "1.3778793811798096\n",
            "2223\n",
            "1.344160556793213\n",
            "2224\n",
            "1.3587391376495361\n",
            "2225\n",
            "1.4170916080474854\n",
            "2226\n",
            "1.336313247680664\n",
            "2227\n",
            "1.3079209327697754\n",
            "2228\n",
            "1.3568615913391113\n",
            "2229\n",
            "1.330245852470398\n",
            "2230\n",
            "1.367417335510254\n",
            "2231\n",
            "1.3627350330352783\n",
            "2232\n",
            "1.393085241317749\n",
            "2233\n",
            "1.3418052196502686\n",
            "2234\n",
            "1.374661922454834\n",
            "2235\n",
            "1.401998519897461\n",
            "2236\n",
            "1.3737543821334839\n",
            "2237\n",
            "1.353450894355774\n",
            "2238\n",
            "1.366119623184204\n",
            "2239\n",
            "1.4229440689086914\n",
            "2240\n",
            "1.3893158435821533\n",
            "2241\n",
            "1.3909428119659424\n",
            "2242\n",
            "1.3968614339828491\n",
            "2243\n",
            "1.3266565799713135\n",
            "2244\n",
            "1.3524208068847656\n",
            "2245\n",
            "1.3833625316619873\n",
            "2246\n",
            "1.3302803039550781\n",
            "2247\n",
            "1.3428322076797485\n",
            "2248\n",
            "1.381637692451477\n",
            "2249\n",
            "1.4132678508758545\n",
            "2250\n",
            "step: 2250, train loss: 1.265, val loss: 1.573\n",
            "1.371519684791565\n",
            "2251\n",
            "1.3898956775665283\n",
            "2252\n",
            "1.3491665124893188\n",
            "2253\n",
            "1.3461370468139648\n",
            "2254\n",
            "1.432457685470581\n",
            "2255\n",
            "1.3753310441970825\n",
            "2256\n",
            "1.3981297016143799\n",
            "2257\n",
            "1.3240764141082764\n",
            "2258\n",
            "1.3117578029632568\n",
            "2259\n",
            "1.328140377998352\n",
            "2260\n",
            "1.3625136613845825\n",
            "2261\n",
            "1.3594799041748047\n",
            "2262\n",
            "1.3873660564422607\n",
            "2263\n",
            "1.355470895767212\n",
            "2264\n",
            "1.3475931882858276\n",
            "2265\n",
            "1.3446643352508545\n",
            "2266\n",
            "1.3784592151641846\n",
            "2267\n",
            "1.3174982070922852\n",
            "2268\n",
            "1.3921539783477783\n",
            "2269\n",
            "1.418952226638794\n",
            "2270\n",
            "1.3457459211349487\n",
            "2271\n",
            "1.3458573818206787\n",
            "2272\n",
            "1.3754544258117676\n",
            "2273\n",
            "1.3669483661651611\n",
            "2274\n",
            "1.3472559452056885\n",
            "2275\n",
            "1.3649392127990723\n",
            "2276\n",
            "1.3696662187576294\n",
            "2277\n",
            "1.3954206705093384\n",
            "2278\n",
            "1.3673908710479736\n",
            "2279\n",
            "1.3827745914459229\n",
            "2280\n",
            "1.3592133522033691\n",
            "2281\n",
            "1.3618403673171997\n",
            "2282\n",
            "1.3751554489135742\n",
            "2283\n",
            "1.3680081367492676\n",
            "2284\n",
            "1.349799394607544\n",
            "2285\n",
            "1.3641959428787231\n",
            "2286\n",
            "1.329478144645691\n",
            "2287\n",
            "1.330452799797058\n",
            "2288\n",
            "1.3757579326629639\n",
            "2289\n",
            "1.3500267267227173\n",
            "2290\n",
            "1.3425933122634888\n",
            "2291\n",
            "1.3470861911773682\n",
            "2292\n",
            "1.3567055463790894\n",
            "2293\n",
            "1.3827266693115234\n",
            "2294\n",
            "1.3862475156784058\n",
            "2295\n",
            "1.3538949489593506\n",
            "2296\n",
            "1.382735013961792\n",
            "2297\n",
            "1.3100543022155762\n",
            "2298\n",
            "1.3724329471588135\n",
            "2299\n",
            "1.331421971321106\n",
            "2300\n",
            "step: 2300, train loss: 1.258, val loss: 1.553\n",
            "1.403740406036377\n",
            "2301\n",
            "1.359786033630371\n",
            "2302\n",
            "1.3649675846099854\n",
            "2303\n",
            "1.3377635478973389\n",
            "2304\n",
            "1.3711235523223877\n",
            "2305\n",
            "1.3471145629882812\n",
            "2306\n",
            "1.321581244468689\n",
            "2307\n",
            "1.3525426387786865\n",
            "2308\n",
            "1.3762156963348389\n",
            "2309\n",
            "1.3284285068511963\n",
            "2310\n",
            "1.3434326648712158\n",
            "2311\n",
            "1.358580470085144\n",
            "2312\n",
            "1.3350220918655396\n",
            "2313\n",
            "1.3306925296783447\n",
            "2314\n",
            "1.4153273105621338\n",
            "2315\n",
            "1.35856032371521\n",
            "2316\n",
            "1.3511639833450317\n",
            "2317\n",
            "1.361250400543213\n",
            "2318\n",
            "1.311193585395813\n",
            "2319\n",
            "1.3506875038146973\n",
            "2320\n",
            "1.3328055143356323\n",
            "2321\n",
            "1.3433732986450195\n",
            "2322\n",
            "1.3840056657791138\n",
            "2323\n",
            "1.3871830701828003\n",
            "2324\n",
            "1.321092963218689\n",
            "2325\n",
            "1.3682422637939453\n",
            "2326\n",
            "1.3753684759140015\n",
            "2327\n",
            "1.3663992881774902\n",
            "2328\n",
            "1.3862378597259521\n",
            "2329\n",
            "1.3832135200500488\n",
            "2330\n",
            "1.3269431591033936\n",
            "2331\n",
            "1.348696231842041\n",
            "2332\n",
            "1.3475648164749146\n",
            "2333\n",
            "1.3662452697753906\n",
            "2334\n",
            "1.3747692108154297\n",
            "2335\n",
            "1.348944902420044\n",
            "2336\n",
            "1.3908512592315674\n",
            "2337\n",
            "1.357297658920288\n",
            "2338\n",
            "1.3978633880615234\n",
            "2339\n",
            "1.4136766195297241\n",
            "2340\n",
            "1.3154829740524292\n",
            "2341\n",
            "1.348479986190796\n",
            "2342\n",
            "1.3321996927261353\n",
            "2343\n",
            "1.3623076677322388\n",
            "2344\n",
            "1.391221284866333\n",
            "2345\n",
            "1.3728396892547607\n",
            "2346\n",
            "1.3702852725982666\n",
            "2347\n",
            "1.3771252632141113\n",
            "2348\n",
            "1.3911621570587158\n",
            "2349\n",
            "1.3514091968536377\n",
            "2350\n",
            "step: 2350, train loss: 1.252, val loss: 1.580\n",
            "1.3286125659942627\n",
            "2351\n",
            "1.3288383483886719\n",
            "2352\n",
            "1.3556371927261353\n",
            "2353\n",
            "1.3358256816864014\n",
            "2354\n",
            "1.3783445358276367\n",
            "2355\n",
            "1.3378345966339111\n",
            "2356\n",
            "1.3832908868789673\n",
            "2357\n",
            "1.3490573167800903\n",
            "2358\n",
            "1.3622312545776367\n",
            "2359\n",
            "1.3508696556091309\n",
            "2360\n",
            "1.328122854232788\n",
            "2361\n",
            "1.3558443784713745\n",
            "2362\n",
            "1.3356752395629883\n",
            "2363\n",
            "1.358634352684021\n",
            "2364\n",
            "1.2997207641601562\n",
            "2365\n",
            "1.3609471321105957\n",
            "2366\n",
            "1.3431987762451172\n",
            "2367\n",
            "1.3281506299972534\n",
            "2368\n",
            "1.3342634439468384\n",
            "2369\n",
            "1.352732539176941\n",
            "2370\n",
            "1.3127521276474\n",
            "2371\n",
            "1.3564705848693848\n",
            "2372\n",
            "1.3635890483856201\n",
            "2373\n",
            "1.33769690990448\n",
            "2374\n",
            "1.3496521711349487\n",
            "2375\n",
            "1.3532906770706177\n",
            "2376\n",
            "1.3251538276672363\n",
            "2377\n",
            "1.3411623239517212\n",
            "2378\n",
            "1.3818023204803467\n",
            "2379\n",
            "1.3600380420684814\n",
            "2380\n",
            "1.292663812637329\n",
            "2381\n",
            "1.3111295700073242\n",
            "2382\n",
            "1.3569161891937256\n",
            "2383\n",
            "1.3865381479263306\n",
            "2384\n",
            "1.3415148258209229\n",
            "2385\n",
            "1.310288429260254\n",
            "2386\n",
            "1.3793797492980957\n",
            "2387\n",
            "1.328918695449829\n",
            "2388\n",
            "1.3405588865280151\n",
            "2389\n",
            "1.3588145971298218\n",
            "2390\n",
            "1.4123117923736572\n",
            "2391\n",
            "1.3250079154968262\n",
            "2392\n",
            "1.3565469980239868\n",
            "2393\n",
            "1.348711609840393\n",
            "2394\n",
            "1.3184032440185547\n",
            "2395\n",
            "1.3552632331848145\n",
            "2396\n",
            "1.3378485441207886\n",
            "2397\n",
            "1.330161452293396\n",
            "2398\n",
            "1.3707695007324219\n",
            "2399\n",
            "1.3913301229476929\n",
            "2400\n",
            "step: 2400, train loss: 1.241, val loss: 1.556\n",
            "1.3259716033935547\n",
            "2401\n",
            "1.3795803785324097\n",
            "2402\n",
            "1.3619763851165771\n",
            "2403\n",
            "1.3412425518035889\n",
            "2404\n",
            "1.3372970819473267\n",
            "2405\n",
            "1.3423532247543335\n",
            "2406\n",
            "1.3256654739379883\n",
            "2407\n",
            "1.3277733325958252\n",
            "2408\n",
            "1.364349126815796\n",
            "2409\n",
            "1.3326246738433838\n",
            "2410\n",
            "1.3270142078399658\n",
            "2411\n",
            "1.3439040184020996\n",
            "2412\n",
            "1.3274247646331787\n",
            "2413\n",
            "1.330399513244629\n",
            "2414\n",
            "1.3490378856658936\n",
            "2415\n",
            "1.3485347032546997\n",
            "2416\n",
            "1.3499464988708496\n",
            "2417\n",
            "1.3331618309020996\n",
            "2418\n",
            "1.3909467458724976\n",
            "2419\n",
            "1.3857989311218262\n",
            "2420\n",
            "1.347238540649414\n",
            "2421\n",
            "1.3330788612365723\n",
            "2422\n",
            "1.3463475704193115\n",
            "2423\n",
            "1.3710914850234985\n",
            "2424\n",
            "1.346433162689209\n",
            "2425\n",
            "1.3826159238815308\n",
            "2426\n",
            "1.3406636714935303\n",
            "2427\n",
            "1.3665709495544434\n",
            "2428\n",
            "1.343684196472168\n",
            "2429\n",
            "1.344865083694458\n",
            "2430\n",
            "1.3211230039596558\n",
            "2431\n",
            "1.3578503131866455\n",
            "2432\n",
            "1.3671514987945557\n",
            "2433\n",
            "1.3338987827301025\n",
            "2434\n",
            "1.2981114387512207\n",
            "2435\n",
            "1.3584959506988525\n",
            "2436\n",
            "1.356407642364502\n",
            "2437\n",
            "1.3238575458526611\n",
            "2438\n",
            "1.3356380462646484\n",
            "2439\n",
            "1.3411136865615845\n",
            "2440\n",
            "1.3536291122436523\n",
            "2441\n",
            "1.3704605102539062\n",
            "2442\n",
            "1.3014112710952759\n",
            "2443\n",
            "1.3102445602416992\n",
            "2444\n",
            "1.3355705738067627\n",
            "2445\n",
            "1.3965198993682861\n",
            "2446\n",
            "1.3459420204162598\n",
            "2447\n",
            "1.3333954811096191\n",
            "2448\n",
            "1.357658863067627\n",
            "2449\n",
            "1.343246340751648\n",
            "2450\n",
            "step: 2450, train loss: 1.249, val loss: 1.568\n",
            "1.331491231918335\n",
            "2451\n",
            "1.3214631080627441\n",
            "2452\n",
            "1.3440871238708496\n",
            "2453\n",
            "1.340686559677124\n",
            "2454\n",
            "1.3513712882995605\n",
            "2455\n",
            "1.3528834581375122\n",
            "2456\n",
            "1.359004020690918\n",
            "2457\n",
            "1.3098275661468506\n",
            "2458\n",
            "1.3192074298858643\n",
            "2459\n",
            "1.332399606704712\n",
            "2460\n",
            "1.3426461219787598\n",
            "2461\n",
            "1.3294857740402222\n",
            "2462\n",
            "1.381400465965271\n",
            "2463\n",
            "1.3713676929473877\n",
            "2464\n",
            "1.3944436311721802\n",
            "2465\n",
            "1.2883914709091187\n",
            "2466\n",
            "1.345644235610962\n",
            "2467\n",
            "1.3214662075042725\n",
            "2468\n",
            "1.3926864862442017\n",
            "2469\n",
            "1.3224557638168335\n",
            "2470\n",
            "1.3216849565505981\n",
            "2471\n",
            "1.3185889720916748\n",
            "2472\n",
            "1.3525663614273071\n",
            "2473\n",
            "1.296883463859558\n",
            "2474\n",
            "1.3149356842041016\n",
            "2475\n",
            "1.357137680053711\n",
            "2476\n",
            "1.3509414196014404\n",
            "2477\n",
            "1.3991570472717285\n",
            "2478\n",
            "1.327368974685669\n",
            "2479\n",
            "1.3513636589050293\n",
            "2480\n",
            "1.3631564378738403\n",
            "2481\n",
            "1.3740267753601074\n",
            "2482\n",
            "1.3526673316955566\n",
            "2483\n",
            "1.3635190725326538\n",
            "2484\n",
            "1.3109130859375\n",
            "2485\n",
            "1.3101086616516113\n",
            "2486\n",
            "1.3771207332611084\n",
            "2487\n",
            "1.3193178176879883\n",
            "2488\n",
            "1.3234530687332153\n",
            "2489\n",
            "1.346463680267334\n",
            "2490\n",
            "1.3602988719940186\n",
            "2491\n",
            "1.3678388595581055\n",
            "2492\n",
            "1.3238685131072998\n",
            "2493\n",
            "1.3449554443359375\n",
            "2494\n",
            "1.3273727893829346\n",
            "2495\n",
            "1.3392839431762695\n",
            "2496\n",
            "1.3335620164871216\n",
            "2497\n",
            "1.3375439643859863\n",
            "2498\n",
            "1.3015172481536865\n",
            "2499\n",
            "1.3283417224884033\n",
            "2500\n",
            "step: 2500, train loss: 1.237, val loss: 1.560\n",
            "1.3256304264068604\n",
            "2501\n",
            "1.3755147457122803\n",
            "2502\n",
            "1.2803945541381836\n",
            "2503\n",
            "1.3290232419967651\n",
            "2504\n",
            "1.3319251537322998\n",
            "2505\n",
            "1.3544297218322754\n",
            "2506\n",
            "1.3255283832550049\n",
            "2507\n",
            "1.331485629081726\n",
            "2508\n",
            "1.331939697265625\n",
            "2509\n",
            "1.3150676488876343\n",
            "2510\n",
            "1.3437368869781494\n",
            "2511\n",
            "1.3243162631988525\n",
            "2512\n",
            "1.349856972694397\n",
            "2513\n",
            "1.368654489517212\n",
            "2514\n",
            "1.325038194656372\n",
            "2515\n",
            "1.319084644317627\n",
            "2516\n",
            "1.3159053325653076\n",
            "2517\n",
            "1.319711685180664\n",
            "2518\n",
            "1.3421645164489746\n",
            "2519\n",
            "1.379406213760376\n",
            "2520\n",
            "1.3546628952026367\n",
            "2521\n",
            "1.3200159072875977\n",
            "2522\n",
            "1.347782850265503\n",
            "2523\n",
            "1.3399914503097534\n",
            "2524\n",
            "1.3313167095184326\n",
            "2525\n",
            "1.3519171476364136\n",
            "2526\n",
            "1.3052222728729248\n",
            "2527\n",
            "1.3405277729034424\n",
            "2528\n",
            "1.333808183670044\n",
            "2529\n",
            "1.3196271657943726\n",
            "2530\n",
            "1.3606858253479004\n",
            "2531\n",
            "1.3742215633392334\n",
            "2532\n",
            "1.4050359725952148\n",
            "2533\n",
            "1.3017890453338623\n",
            "2534\n",
            "1.3412716388702393\n",
            "2535\n",
            "1.3535566329956055\n",
            "2536\n",
            "1.3895621299743652\n",
            "2537\n",
            "1.3163546323776245\n",
            "2538\n",
            "1.3166993856430054\n",
            "2539\n",
            "1.386789321899414\n",
            "2540\n",
            "1.326294183731079\n",
            "2541\n",
            "1.3527392148971558\n",
            "2542\n",
            "1.322346568107605\n",
            "2543\n",
            "1.3520405292510986\n",
            "2544\n",
            "1.3326365947723389\n",
            "2545\n",
            "1.3360214233398438\n",
            "2546\n",
            "1.3386486768722534\n",
            "2547\n",
            "1.3008602857589722\n",
            "2548\n",
            "1.2969557046890259\n",
            "2549\n",
            "1.29740309715271\n",
            "2550\n",
            "step: 2550, train loss: 1.233, val loss: 1.543\n",
            "1.3458828926086426\n",
            "2551\n",
            "1.3441475629806519\n",
            "2552\n",
            "1.3295460939407349\n",
            "2553\n",
            "1.2824363708496094\n",
            "2554\n",
            "1.334729790687561\n",
            "2555\n",
            "1.3243498802185059\n",
            "2556\n",
            "1.3429532051086426\n",
            "2557\n",
            "1.3459548950195312\n",
            "2558\n",
            "1.3101806640625\n",
            "2559\n",
            "1.343359112739563\n",
            "2560\n",
            "1.3447532653808594\n",
            "2561\n",
            "1.328437089920044\n",
            "2562\n",
            "1.3147242069244385\n",
            "2563\n",
            "1.3478025197982788\n",
            "2564\n",
            "1.2738394737243652\n",
            "2565\n",
            "1.319648027420044\n",
            "2566\n",
            "1.2922629117965698\n",
            "2567\n",
            "1.3372222185134888\n",
            "2568\n",
            "1.2888139486312866\n",
            "2569\n",
            "1.364208698272705\n",
            "2570\n",
            "1.3391835689544678\n",
            "2571\n",
            "1.3165242671966553\n",
            "2572\n",
            "1.2952507734298706\n",
            "2573\n",
            "1.2928578853607178\n",
            "2574\n",
            "1.3419862985610962\n",
            "2575\n",
            "1.3415555953979492\n",
            "2576\n",
            "1.3237041234970093\n",
            "2577\n",
            "1.3054416179656982\n",
            "2578\n",
            "1.3103916645050049\n",
            "2579\n",
            "1.3265143632888794\n",
            "2580\n",
            "1.333254337310791\n",
            "2581\n",
            "1.3789410591125488\n",
            "2582\n",
            "1.3321672677993774\n",
            "2583\n",
            "1.3271629810333252\n",
            "2584\n",
            "1.3220455646514893\n",
            "2585\n",
            "1.2826762199401855\n",
            "2586\n",
            "1.3403732776641846\n",
            "2587\n",
            "1.4116090536117554\n",
            "2588\n",
            "1.3382055759429932\n",
            "2589\n",
            "1.3453015089035034\n",
            "2590\n",
            "1.3352088928222656\n",
            "2591\n",
            "1.3574333190917969\n",
            "2592\n",
            "1.3139078617095947\n",
            "2593\n",
            "1.3263834714889526\n",
            "2594\n",
            "1.3250354528427124\n",
            "2595\n",
            "1.3586276769638062\n",
            "2596\n",
            "1.3076651096343994\n",
            "2597\n",
            "1.3502775430679321\n",
            "2598\n",
            "1.3222651481628418\n",
            "2599\n",
            "1.2738488912582397\n",
            "2600\n",
            "step: 2600, train loss: 1.224, val loss: 1.553\n",
            "1.3018475770950317\n",
            "2601\n",
            "1.3125827312469482\n",
            "2602\n",
            "1.3745064735412598\n",
            "2603\n",
            "1.3284621238708496\n",
            "2604\n",
            "1.299062728881836\n",
            "2605\n",
            "1.3274025917053223\n",
            "2606\n",
            "1.361637830734253\n",
            "2607\n",
            "1.3001205921173096\n",
            "2608\n",
            "1.3170541524887085\n",
            "2609\n",
            "1.3387904167175293\n",
            "2610\n",
            "1.3209335803985596\n",
            "2611\n",
            "1.3414759635925293\n",
            "2612\n",
            "1.3375184535980225\n",
            "2613\n",
            "1.3341529369354248\n",
            "2614\n",
            "1.355855941772461\n",
            "2615\n",
            "1.3064093589782715\n",
            "2616\n",
            "1.3254644870758057\n",
            "2617\n",
            "1.3034217357635498\n",
            "2618\n",
            "1.3334290981292725\n",
            "2619\n",
            "1.2993288040161133\n",
            "2620\n",
            "1.3192851543426514\n",
            "2621\n",
            "1.2724839448928833\n",
            "2622\n",
            "1.3427761793136597\n",
            "2623\n",
            "1.3340437412261963\n",
            "2624\n",
            "1.3579065799713135\n",
            "2625\n",
            "1.3299658298492432\n",
            "2626\n",
            "1.2855403423309326\n",
            "2627\n",
            "1.3279720544815063\n",
            "2628\n",
            "1.3001644611358643\n",
            "2629\n",
            "1.2925759553909302\n",
            "2630\n",
            "1.3135106563568115\n",
            "2631\n",
            "1.2949435710906982\n",
            "2632\n",
            "1.296813726425171\n",
            "2633\n",
            "1.334796667098999\n",
            "2634\n",
            "1.3107621669769287\n",
            "2635\n",
            "1.3153390884399414\n",
            "2636\n",
            "1.3135044574737549\n",
            "2637\n",
            "1.2880938053131104\n",
            "2638\n",
            "1.273108720779419\n",
            "2639\n",
            "1.3094526529312134\n",
            "2640\n",
            "1.3817411661148071\n",
            "2641\n",
            "1.2457963228225708\n",
            "2642\n",
            "1.3284870386123657\n",
            "2643\n",
            "1.317918300628662\n",
            "2644\n",
            "1.2888779640197754\n",
            "2645\n",
            "1.3659117221832275\n",
            "2646\n",
            "1.3178874254226685\n",
            "2647\n",
            "1.3296453952789307\n",
            "2648\n",
            "1.3228671550750732\n",
            "2649\n",
            "1.332747220993042\n",
            "2650\n",
            "step: 2650, train loss: 1.216, val loss: 1.546\n",
            "1.3508167266845703\n",
            "2651\n",
            "1.3223814964294434\n",
            "2652\n",
            "1.2830734252929688\n",
            "2653\n",
            "1.323833703994751\n",
            "2654\n",
            "1.2828524112701416\n",
            "2655\n",
            "1.3434193134307861\n",
            "2656\n",
            "1.3589931726455688\n",
            "2657\n",
            "1.3286588191986084\n",
            "2658\n",
            "1.3211407661437988\n",
            "2659\n",
            "1.286835789680481\n",
            "2660\n",
            "1.3058910369873047\n",
            "2661\n",
            "1.3865872621536255\n",
            "2662\n",
            "1.335121512413025\n",
            "2663\n",
            "1.3057142496109009\n",
            "2664\n",
            "1.3080246448516846\n",
            "2665\n",
            "1.3336013555526733\n",
            "2666\n",
            "1.3123514652252197\n",
            "2667\n",
            "1.3102819919586182\n",
            "2668\n",
            "1.2951154708862305\n",
            "2669\n",
            "1.3258453607559204\n",
            "2670\n",
            "1.348334789276123\n",
            "2671\n",
            "1.3337833881378174\n",
            "2672\n",
            "1.329404354095459\n",
            "2673\n",
            "1.3245339393615723\n",
            "2674\n",
            "1.3580938577651978\n",
            "2675\n",
            "1.3189620971679688\n",
            "2676\n",
            "1.323359727859497\n",
            "2677\n",
            "1.3238623142242432\n",
            "2678\n",
            "1.385961890220642\n",
            "2679\n",
            "1.2935024499893188\n",
            "2680\n",
            "1.3169922828674316\n",
            "2681\n",
            "1.3476769924163818\n",
            "2682\n",
            "1.34464693069458\n",
            "2683\n",
            "1.313551425933838\n",
            "2684\n",
            "1.3340587615966797\n",
            "2685\n",
            "1.3440355062484741\n",
            "2686\n",
            "1.3007662296295166\n",
            "2687\n",
            "1.3108068704605103\n",
            "2688\n",
            "1.2813115119934082\n",
            "2689\n",
            "1.3495347499847412\n",
            "2690\n",
            "1.3149641752243042\n",
            "2691\n",
            "1.3263511657714844\n",
            "2692\n",
            "1.3061442375183105\n",
            "2693\n",
            "1.264175295829773\n",
            "2694\n",
            "1.3454456329345703\n",
            "2695\n",
            "1.3328611850738525\n",
            "2696\n",
            "1.3191449642181396\n",
            "2697\n",
            "1.3259410858154297\n",
            "2698\n",
            "1.2965818643569946\n",
            "2699\n",
            "1.333547592163086\n",
            "2700\n",
            "step: 2700, train loss: 1.212, val loss: 1.558\n",
            "1.2923822402954102\n",
            "2701\n",
            "1.3215724229812622\n",
            "2702\n",
            "1.3026866912841797\n",
            "2703\n",
            "1.3129018545150757\n",
            "2704\n",
            "1.2755558490753174\n",
            "2705\n",
            "1.3339498043060303\n",
            "2706\n",
            "1.2895376682281494\n",
            "2707\n",
            "1.3129959106445312\n",
            "2708\n",
            "1.3349277973175049\n",
            "2709\n",
            "1.3285588026046753\n",
            "2710\n",
            "1.3081943988800049\n",
            "2711\n",
            "1.297690510749817\n",
            "2712\n",
            "1.3371562957763672\n",
            "2713\n",
            "1.2864842414855957\n",
            "2714\n",
            "1.31855046749115\n",
            "2715\n",
            "1.3515597581863403\n",
            "2716\n",
            "1.3498259782791138\n",
            "2717\n",
            "1.3527491092681885\n",
            "2718\n",
            "1.3983545303344727\n",
            "2719\n",
            "1.3085529804229736\n",
            "2720\n",
            "1.34108567237854\n",
            "2721\n",
            "1.3124217987060547\n",
            "2722\n",
            "1.314967393875122\n",
            "2723\n",
            "1.2968623638153076\n",
            "2724\n",
            "1.3146357536315918\n",
            "2725\n",
            "1.282827377319336\n",
            "2726\n",
            "1.2997901439666748\n",
            "2727\n",
            "1.3004816770553589\n",
            "2728\n",
            "1.3044369220733643\n",
            "2729\n",
            "1.3347053527832031\n",
            "2730\n",
            "1.3400983810424805\n",
            "2731\n",
            "1.3439276218414307\n",
            "2732\n",
            "1.3113906383514404\n",
            "2733\n",
            "1.2765390872955322\n",
            "2734\n",
            "1.3181849718093872\n",
            "2735\n",
            "1.3411697149276733\n",
            "2736\n",
            "1.2771210670471191\n",
            "2737\n",
            "1.315255045890808\n",
            "2738\n",
            "1.3474643230438232\n",
            "2739\n",
            "1.287412405014038\n",
            "2740\n",
            "1.31600022315979\n",
            "2741\n",
            "1.3236982822418213\n",
            "2742\n",
            "1.3186054229736328\n",
            "2743\n",
            "1.3150306940078735\n",
            "2744\n",
            "1.3044506311416626\n",
            "2745\n",
            "1.3068243265151978\n",
            "2746\n",
            "1.2566003799438477\n",
            "2747\n",
            "1.248857855796814\n",
            "2748\n",
            "1.3489776849746704\n",
            "2749\n",
            "1.3334286212921143\n",
            "2750\n",
            "step: 2750, train loss: 1.219, val loss: 1.550\n",
            "1.3511877059936523\n",
            "2751\n",
            "1.2885422706604004\n",
            "2752\n",
            "1.2924987077713013\n",
            "2753\n",
            "1.300305724143982\n",
            "2754\n",
            "1.3171031475067139\n",
            "2755\n",
            "1.2754827737808228\n",
            "2756\n",
            "1.308976173400879\n",
            "2757\n",
            "1.315572738647461\n",
            "2758\n",
            "1.306718349456787\n",
            "2759\n",
            "1.308474063873291\n",
            "2760\n",
            "1.235201120376587\n",
            "2761\n",
            "1.306133508682251\n",
            "2762\n",
            "1.2779560089111328\n",
            "2763\n",
            "1.3431260585784912\n",
            "2764\n",
            "1.3273131847381592\n",
            "2765\n",
            "1.297351598739624\n",
            "2766\n",
            "1.2895545959472656\n",
            "2767\n",
            "1.3429625034332275\n",
            "2768\n",
            "1.302807092666626\n",
            "2769\n",
            "1.3086955547332764\n",
            "2770\n",
            "1.3057000637054443\n",
            "2771\n",
            "1.3293193578720093\n",
            "2772\n",
            "1.2777832746505737\n",
            "2773\n",
            "1.3202483654022217\n",
            "2774\n",
            "1.2833094596862793\n",
            "2775\n",
            "1.2823843955993652\n",
            "2776\n",
            "1.3113086223602295\n",
            "2777\n",
            "1.310630202293396\n",
            "2778\n",
            "1.3006876707077026\n",
            "2779\n",
            "1.3090506792068481\n",
            "2780\n",
            "1.2392781972885132\n",
            "2781\n",
            "1.3378986120224\n",
            "2782\n",
            "1.2864360809326172\n",
            "2783\n",
            "1.3084231615066528\n",
            "2784\n",
            "1.3033807277679443\n",
            "2785\n",
            "1.2944368124008179\n",
            "2786\n",
            "1.3435137271881104\n",
            "2787\n",
            "1.3339307308197021\n",
            "2788\n",
            "1.2742679119110107\n",
            "2789\n",
            "1.29149329662323\n",
            "2790\n",
            "1.2561135292053223\n",
            "2791\n",
            "1.3482978343963623\n",
            "2792\n",
            "1.3336350917816162\n",
            "2793\n",
            "1.262721300125122\n",
            "2794\n",
            "1.290842056274414\n",
            "2795\n",
            "1.3028678894042969\n",
            "2796\n",
            "1.3058052062988281\n",
            "2797\n",
            "1.3126282691955566\n",
            "2798\n",
            "1.3027148246765137\n",
            "2799\n",
            "1.3074390888214111\n",
            "2800\n",
            "step: 2800, train loss: 1.204, val loss: 1.540\n",
            "1.3377799987792969\n",
            "2801\n",
            "1.2724281549453735\n",
            "2802\n",
            "1.3019486665725708\n",
            "2803\n",
            "1.2945804595947266\n",
            "2804\n",
            "1.3452255725860596\n",
            "2805\n",
            "1.3185608386993408\n",
            "2806\n",
            "1.337880253791809\n",
            "2807\n",
            "1.333134412765503\n",
            "2808\n",
            "1.3477673530578613\n",
            "2809\n",
            "1.300873041152954\n",
            "2810\n",
            "1.2698088884353638\n",
            "2811\n",
            "1.3158878087997437\n",
            "2812\n",
            "1.2929408550262451\n",
            "2813\n",
            "1.293104887008667\n",
            "2814\n",
            "1.3393328189849854\n",
            "2815\n",
            "1.3159468173980713\n",
            "2816\n",
            "1.3550770282745361\n",
            "2817\n",
            "1.2654293775558472\n",
            "2818\n",
            "1.3041752576828003\n",
            "2819\n",
            "1.2662442922592163\n",
            "2820\n",
            "1.2890886068344116\n",
            "2821\n",
            "1.2542083263397217\n",
            "2822\n",
            "1.3030157089233398\n",
            "2823\n",
            "1.301999568939209\n",
            "2824\n",
            "1.2589530944824219\n",
            "2825\n",
            "1.285776138305664\n",
            "2826\n",
            "1.2920126914978027\n",
            "2827\n",
            "1.3069446086883545\n",
            "2828\n",
            "1.3324756622314453\n",
            "2829\n",
            "1.2735817432403564\n",
            "2830\n",
            "1.3175373077392578\n",
            "2831\n",
            "1.3208234310150146\n",
            "2832\n",
            "1.270354986190796\n",
            "2833\n",
            "1.3403393030166626\n",
            "2834\n",
            "1.2746343612670898\n",
            "2835\n",
            "1.3734278678894043\n",
            "2836\n",
            "1.3318355083465576\n",
            "2837\n",
            "1.3108948469161987\n",
            "2838\n",
            "1.283205270767212\n",
            "2839\n",
            "1.314866304397583\n",
            "2840\n",
            "1.323875069618225\n",
            "2841\n",
            "1.2684588432312012\n",
            "2842\n",
            "1.288939356803894\n",
            "2843\n",
            "1.3078850507736206\n",
            "2844\n",
            "1.331200122833252\n",
            "2845\n",
            "1.320448875427246\n",
            "2846\n",
            "1.3330702781677246\n",
            "2847\n",
            "1.2963016033172607\n",
            "2848\n",
            "1.2891874313354492\n",
            "2849\n",
            "1.3243367671966553\n",
            "2850\n",
            "step: 2850, train loss: 1.210, val loss: 1.518\n",
            "1.2827599048614502\n",
            "2851\n",
            "1.2795054912567139\n",
            "2852\n",
            "1.3056535720825195\n",
            "2853\n",
            "1.2970950603485107\n",
            "2854\n",
            "1.3450247049331665\n",
            "2855\n",
            "1.2939881086349487\n",
            "2856\n",
            "1.330662488937378\n",
            "2857\n",
            "1.3258836269378662\n",
            "2858\n",
            "1.2824138402938843\n",
            "2859\n",
            "1.3075083494186401\n",
            "2860\n",
            "1.3178465366363525\n",
            "2861\n",
            "1.292914867401123\n",
            "2862\n",
            "1.3067214488983154\n",
            "2863\n",
            "1.2917040586471558\n",
            "2864\n",
            "1.3319518566131592\n",
            "2865\n",
            "1.313891887664795\n",
            "2866\n",
            "1.3001337051391602\n",
            "2867\n",
            "1.2740046977996826\n",
            "2868\n",
            "1.2669295072555542\n",
            "2869\n",
            "1.354971170425415\n",
            "2870\n",
            "1.2992092370986938\n",
            "2871\n",
            "1.3058314323425293\n",
            "2872\n",
            "1.3096598386764526\n",
            "2873\n",
            "1.2800737619400024\n",
            "2874\n",
            "1.3204443454742432\n",
            "2875\n",
            "1.3226652145385742\n",
            "2876\n",
            "1.2798362970352173\n",
            "2877\n",
            "1.2804789543151855\n",
            "2878\n",
            "1.298572301864624\n",
            "2879\n",
            "1.3190175294876099\n",
            "2880\n",
            "1.2913326025009155\n",
            "2881\n",
            "1.279771327972412\n",
            "2882\n",
            "1.3332157135009766\n",
            "2883\n",
            "1.2641243934631348\n",
            "2884\n",
            "1.3295068740844727\n",
            "2885\n",
            "1.2396456003189087\n",
            "2886\n",
            "1.319101333618164\n",
            "2887\n",
            "1.331955909729004\n",
            "2888\n",
            "1.3098949193954468\n",
            "2889\n",
            "1.347407341003418\n",
            "2890\n",
            "1.326720118522644\n",
            "2891\n",
            "1.2738893032073975\n",
            "2892\n",
            "1.2997610569000244\n",
            "2893\n",
            "1.3085976839065552\n",
            "2894\n",
            "1.2879843711853027\n",
            "2895\n",
            "1.3127386569976807\n",
            "2896\n",
            "1.3073692321777344\n",
            "2897\n",
            "1.2622063159942627\n",
            "2898\n",
            "1.264923095703125\n",
            "2899\n",
            "1.2976192235946655\n",
            "2900\n",
            "step: 2900, train loss: 1.205, val loss: 1.523\n",
            "1.2658705711364746\n",
            "2901\n",
            "1.3033735752105713\n",
            "2902\n",
            "1.3257426023483276\n",
            "2903\n",
            "1.3499515056610107\n",
            "2904\n",
            "1.297975778579712\n",
            "2905\n",
            "1.3284943103790283\n",
            "2906\n",
            "1.2833621501922607\n",
            "2907\n",
            "1.287038803100586\n",
            "2908\n",
            "1.308296799659729\n",
            "2909\n",
            "1.3034172058105469\n",
            "2910\n",
            "1.2553156614303589\n",
            "2911\n",
            "1.280590534210205\n",
            "2912\n",
            "1.295774221420288\n",
            "2913\n",
            "1.2813265323638916\n",
            "2914\n",
            "1.3508204221725464\n",
            "2915\n",
            "1.2860684394836426\n",
            "2916\n",
            "1.2802470922470093\n",
            "2917\n",
            "1.3599791526794434\n",
            "2918\n",
            "1.3253666162490845\n",
            "2919\n",
            "1.294875144958496\n",
            "2920\n",
            "1.3083564043045044\n",
            "2921\n",
            "1.321225881576538\n",
            "2922\n",
            "1.2737720012664795\n",
            "2923\n",
            "1.2918553352355957\n",
            "2924\n",
            "1.2986946105957031\n",
            "2925\n",
            "1.2939471006393433\n",
            "2926\n",
            "1.3157374858856201\n",
            "2927\n",
            "1.2976093292236328\n",
            "2928\n",
            "1.2771930694580078\n",
            "2929\n",
            "1.305641770362854\n",
            "2930\n",
            "1.3429734706878662\n",
            "2931\n",
            "1.252810001373291\n",
            "2932\n",
            "1.2670352458953857\n",
            "2933\n",
            "1.2936097383499146\n",
            "2934\n",
            "1.3168282508850098\n",
            "2935\n",
            "1.2999378442764282\n",
            "2936\n",
            "1.2911386489868164\n",
            "2937\n",
            "1.325830101966858\n",
            "2938\n",
            "1.2638880014419556\n",
            "2939\n",
            "1.2652956247329712\n",
            "2940\n",
            "1.3164352178573608\n",
            "2941\n",
            "1.274539589881897\n",
            "2942\n",
            "1.3190758228302002\n",
            "2943\n",
            "1.2951900959014893\n",
            "2944\n",
            "1.3053922653198242\n",
            "2945\n",
            "1.3212555646896362\n",
            "2946\n",
            "1.3157877922058105\n",
            "2947\n",
            "1.3149627447128296\n",
            "2948\n",
            "1.2849977016448975\n",
            "2949\n",
            "1.3013341426849365\n",
            "2950\n",
            "step: 2950, train loss: 1.192, val loss: 1.520\n",
            "1.3039734363555908\n",
            "2951\n",
            "1.3002749681472778\n",
            "2952\n",
            "1.2838659286499023\n",
            "2953\n",
            "1.2854642868041992\n",
            "2954\n",
            "1.2880762815475464\n",
            "2955\n",
            "1.3090026378631592\n",
            "2956\n",
            "1.2872000932693481\n",
            "2957\n",
            "1.3153252601623535\n",
            "2958\n",
            "1.2447893619537354\n",
            "2959\n",
            "1.2876501083374023\n",
            "2960\n",
            "1.30299973487854\n",
            "2961\n",
            "1.309375524520874\n",
            "2962\n",
            "1.2943452596664429\n",
            "2963\n",
            "1.2840814590454102\n",
            "2964\n",
            "1.2922396659851074\n",
            "2965\n",
            "1.2835360765457153\n",
            "2966\n",
            "1.2770806550979614\n",
            "2967\n",
            "1.3022276163101196\n",
            "2968\n",
            "1.2765300273895264\n",
            "2969\n",
            "1.3004753589630127\n",
            "2970\n",
            "1.2999681234359741\n",
            "2971\n",
            "1.2278361320495605\n",
            "2972\n",
            "1.2334216833114624\n",
            "2973\n",
            "1.2837793827056885\n",
            "2974\n",
            "1.312238097190857\n",
            "2975\n",
            "1.3003554344177246\n",
            "2976\n",
            "1.2725391387939453\n",
            "2977\n",
            "1.278017282485962\n",
            "2978\n",
            "1.2806771993637085\n",
            "2979\n",
            "1.2815687656402588\n",
            "2980\n",
            "1.2853964567184448\n",
            "2981\n",
            "1.2564704418182373\n",
            "2982\n",
            "1.23177170753479\n",
            "2983\n",
            "1.3170292377471924\n",
            "2984\n",
            "1.2930517196655273\n",
            "2985\n",
            "1.2797515392303467\n",
            "2986\n",
            "1.2567551136016846\n",
            "2987\n",
            "1.3028035163879395\n",
            "2988\n",
            "1.265541911125183\n",
            "2989\n",
            "1.2938708066940308\n",
            "2990\n",
            "1.3616023063659668\n",
            "2991\n",
            "1.2758498191833496\n",
            "2992\n",
            "1.2872929573059082\n",
            "2993\n",
            "1.275768518447876\n",
            "2994\n",
            "1.2829164266586304\n",
            "2995\n",
            "1.277097463607788\n",
            "2996\n",
            "1.30552077293396\n",
            "2997\n",
            "1.2853899002075195\n",
            "2998\n",
            "1.303621530532837\n",
            "2999\n",
            "1.2944340705871582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation\n",
        "* After training, the model can:\n",
        "   * Start from some input text.\n",
        "   * Autoregressively predict the next character.\n",
        "   * Build up new sequences of text."
      ],
      "metadata": {
        "id": "DEU6npmx6FYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Hello! Can you see me?'\n",
        "context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
        "generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=100)[0].tolist())\n",
        "print(generated_chars)\n"
      ],
      "metadata": {
        "id": "R2J_7ZRcrho3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5628a767-668a-4230-8923-cb6128b85b9f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! Can you see me? Have spores were more alone\n",
            "to all, sometily. I be a horror, descending that I had suffered\n",
            "acced. \n"
          ]
        }
      ]
    }
  ]
}